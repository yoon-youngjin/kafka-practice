# 카프카 프로듀서 애플리케이션 개발

프로듀서는 데이터를 전송할 때 리더 파티션을 가지고 있는 카프카 브로커와 직접 통신한다.
프로듀서는 카프카 브로커로 데이터를 전송할 때 내부적으로 파티셔너, 배치 생성 단계를 거친다.

> 리더 파티션 : 프로듀서가 보낸 데이터를 저장하는 역할
> 
> 팔로워 파티션 : 리더 파티션의 데이터를 복제하는 역할

### 프로듀서 내부 구조

<img width="534" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/7c83c0fb-0001-4659-8f9c-625f0ae48762">

- ProducerRecord : 포듀서에서 생성하는 레코드. 오프셋은 미포함
  - 오프셋은 카프카의 특정 파티션에 데이터가 저장된 후 지정된다.
  - 토픽과 메시지 값만 존재해도 데이터를 전송하는데 문제없다.
- send() : 레코드를 전송 요청 메서드
- Partitioner : 어느 파티션으로 전송할지 지정하는 파티셔너. 기본값은로 DefaultPartitioner(UniformStickyPartitioner)로 설정
  - 메시지 키에 따라서 파티션이 배정되는데, 어떤 파티션에 보낼지 결정하는 주체가 파티셔너이다.
- Accumulator : 배치로 묶어 전송할 데이터를 모으는 버퍼
  - 한번에 데이터를 묶어서 전송함으로써 네트워크 낭비를 줄일 수 있다.
- Sender : 브로커와 통신하여 데이터를 전송하는 주체

## 파티셔너

프로듀서 API를 사용하면 'UniformStickyPartitioner', 'RoundRobinPartitioner' 2개 파티셔너를 제공한다. 
카프카 클라이언트 라이브러리 2.5.0 버전에서 파티셔너를 지정하지 않은 경우 UniformStickyPartitioner가 피티셔너로 기본 설정된다.

**메시지 키가 있을 경우 동작**
- UniformStickyPartitioner와 RoundRobinPartitioner 둘 다 메시지 키가 있을 때는 메시지 키의 해시값과 파티션을 매칭하여 레코드를 전송
  - 동일한 메시지 키가 존재하는 레코드는 동일한 파티션 번호에 전달
- 만약 파티션 개수가 변경될 경우 메시지 키와 파티션 번호 매칭은 깨지게 됨 (해시값이 달라짐)

**메시지 키가 없을 경우 동작**

메시지 키가 없을 때는 파티션에 최대한 동일하게 분배하는 로직이 들어있는데 UniformStickyPartitioner는 RoundRobinPartitioner의 단점을 개선하였다는 점이 다르다.
- RoundRobinPartitioner : ProducerRecord가 들어오는 대로 파티션을 순회하면서 전송한다. Accumulator에서 묶이는 정도가 적기 때문에 전송 성능이 낮다
- UniformStickyPartitioner : Accumulator에서 레코드들이 배치로 묶일 때까지 기다렸다가 전송한다. RoundRobinPartitioner에 비해 향상된 성능을 가진다.

### 프로듀서의 커스텀 파티셔너

카프카 클라이언트 라이브러리에서는 사용자 지정 파티셔너를 생성하기 위한 Partitioner 인터페이스를 제공한다.
Partitioner 인터페이스를 상속받은 사용자 정의 클래스에서 메시지 키 또는 메시지값에 따른 파티션 지정 로직을 적용할수도 있다. 
- 현재는 메시지 키로만 해싱을 하고 있지만 key + value 조합으로 해싱하는 등의 커스텀이 가능하다
- 또는 message key에 "서울" 이라고 들어오면 항상 0번 파티션으로 전송해라. (파티션 크기가 늘어도 변경X)

파티셔너를 통해 파티션이 지정된 데이터는 어큐뮬레이터에 버퍼로 쌓인다. 센더 스레드는 어큐뮬레이터에 쌓인 배치 데이터를 가져가 카프카 브로커로 전송한다.

## 프로듀서 주요 옵션 소개

### 필수 옵션

- bootstrap.servers: 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 `호스트 이름:포트`를 1개 이상 작성한다. 2개 이상 브로커 정보를 입력하여 일부 브로커에 이슈가 발생하더라도 접속하는 데에 이슈가 없도록 설정 가능하다.
- key.serializer: 레코드의 메시지 키를 직렬화하는 클래스를 지정한다.
- value.serializer: 레코드의 메시지 값을 직렬화하는 클래스를 지정한다.

### 선택 옵션(default값 존재)

- acks: 프로듀서가 전송한 데이터가 브로커들에 정상적으로 저장되었는지 전송 성공 여부를 확인하는 데에 사용하는 옵션이다. 0, 1, -1(all) 중 하나로 설정할 수 있고, 기본값을 1이다.
  - 프로듀서는 리더 브로카에 데이터를 전달하는데, 이때 데이터가 리더 파티션에만 저장되었는지(1) 리더, 팔로워 파티션 모두 저장되었는지, 전혀 확인하지 않는지에 따라 값이 다르다.
- linger.ms: 어큐뮬레이터에 존재하는 배치를 전송하기 전까지 기다리는 최소 시간이다. 기본값은 0이다.
  - 해당 값을 0보다 크게 잡으면 일부 지연은 발생하지만 배치로 묶어서 전송하기 때문에 네트워크 사용량을 줄일 수 있다.
- retries: 브로커로부터 에러를 받고 난 뒤 재전송을 시도하는 횟수를 지정한다. 기번값은 2147483647이다.
  - 굳이 재전송이 필요하지 않다면 해당 값을 0으로 하거나 작은 값으로 지정한다.
- max.in.flight.requests.per.connection: 한 번에 요청하는 최대 커넥션 개수이다. 설정된 값만큼 동시에 전달 요청을 수행한다. 기본값은 5이다.
  - sender를 통해서 데이터를 전송할 때 sender 쓰레드를 몇개로 설정할지와 비슷하다.
  - 브로커와 맺는 커넥션 개수
- partitioner.class: 레코드를 파티션에 전송할 때 적용하는 파티셔너 클래스를 지정한다. 기본값은 org.apache.kafka.clients.producer.internals.DefaultPartitioner이다.
- enable.idempotence: 멱등성 프로듀서로 동작할지 여부를 설정한다. 기본값은 false이다.
  - 프로듀서와 브로커가 통신할 때 특정 이슈(네트워크 오류)로 인해서 프로듀서가 데이터를 중복해서 전달할 수 있는데, 해당 기능을 수행할지 지정하는 옵션이다.
  - 2.x.x에서는 기본값이 false이지만 3.x.x에서는 true
- transactional.id: 프로듀서가 레코드를 전송할 때 레코드를 트랜잭션 단위로 묶을지 여부를 설정한다. 기본값은 null이다.
  - transactional.id를 지정하게되면 자동으로 enable.idempotence은 true가 된다.
  - transactional.id를 지정하게되면 트랜잭션 프로듀서라고 부른다.

## ISR(In-Sync-Replicas)와 acks 옵션

<img width="465" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/25a4a571-2f21-4f06-a588-02e78fdbda83">

ISR은 리더 파티션과 팔로워 파티션이 모두 싱크가 된 상태를 뜻한다.
복제 개수가 2인 토픽을 가정해 보자. 이 토픽에는 리더 파티션 1개와 팔로워 파티션이 1개가 존재할 것이다. 리더 파티션에 0부터 3의 오프셋이 있다고 가정할 때, 팔로워 파티션에 동기화가 완료되려면 0부터 3까지 오프셋이 존재해야 한다.
동기화가 완료됐다는 의미는 리더 파티션의 모든 데이터가 팔로워 파티션에 복제된 상태를 말하기 때문이다. 

<img width="355" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/590db3d7-0ae5-47a4-827f-80110a688e49">

ISR이라는 용어가 나온 이유는 팔로워 파티션이 리더 파티션으로부터 데이터를 복제하는 데에 시간이 걸리기 때문이다. 프로듀서가 특정 파티션에 데이터를 저장하는 작업은 리더 파티션을 통해 처리한다.
이때 리더 파티션에 새로운 레코드가 추가되어 오프셋이 증가하면 팔로워 파티션이 위치한 브로커는 리더 파티션의 데이터를 복제한다.
리더 파티션에 데이터가 적재된 이후 팔로워 파티션이 복제하는 시간차 때문에 리더 파티션과 팔로워 파티션 간에 오프셋 차이가 발생한다.

### acks

카프카 프로듀서의 acks 옵션은 0, 1, all(또는 -1) 값을 가질 수 있다. 이 옵션을 통해 프로듀서가 전송한 데이터가 카프카 클러스터에 얼마나 신뢰성 높게 저장할지 지정할 수 있다.
그리고 acks 옵션에 따라 성능이 달라질 수 있으므로 acks 옵션에 따른 카프카 동작 방식을 상세히 알고 설정해야 한다. 
복제 개수가 1인 경우 acks 옵션에 따른 성능 변화는 크지 않다. 그러나 안정적으로 데이터를 운영하기 위해서는 복제 개수가 2이상으로 운영하는 경우가 대부분이기 때문에 여기서는 복제 개수는 2 이상인 경우에 각 acks별 동작 방식에 대해 알아본다.

**acks=0**

<img width="334" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/c040423d-af0c-4f0d-8d1f-dc04f98e2600">

프로듀서가 리더 파티션으로 데이터를 전송했을 때 리더 파티션으로 데이터가 저장되었는지 확인하지 않는다는 뜻이다.
리더 파티션은 데이터가 저장된 이후에 데이터가 몇 번째 오프셋에 저장되었는지 리턴하는데, acks가 0으로 설정되어 있다면 프로듀서는 리더 파티션에 데이터가 저장되었는지 여부에 대한 응답 값을 받지 않는다.
데이터 전송 속도는 가장 빠르다. 데이터 일부에 유실이 발생하더라도 전송 속도가 중요한 경우네는 이 옵션값을 사용하면 좋다.

예를 들어 GPS 데이터의 경우에는 데이터 유실이 발생하더라도 전체 경로가 파악되기 때문에 해당 옵션을 사용해볼 수 있다.

**acks=1**

<img width="308" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/042180fd-3576-4aaf-b9b4-3cc42715b789">

프로듀서는 보낸 데이터가 리더 파티션에만 정상적으로 적재되었는지 확인한다.
만약 리더 파티션에 정상적으로 적재되지 않았다면 리더 파티션에 적재될 때까지 재시도할 수 있다. 그러나 리더 파티션에 적재되었음을 보장하더라도 데이터는 유실될 수 있다.
왜냐하면 복제 개수를 2 이상으로 운영할 경우 리더 파티션에 적재가 완료되어도 팔로워 파티션에는 아직 데이터 동기화되지 않을 수 있는데, 팔로워 파티션이 데이터를 복제하기 직전에 리더 파티션에 있는 브로커에 장애가 발생하면 동기화되지 못한 데이터가 유실될 수 있기 때문이다.
하지만 이러한 상황은 드물다. 따라서 일반적인 상황에서는 acks=1로 설정해서 사용한다.

acks=0에 비해서는 신뢰도를 높일 수 있지만 리더 파티션에 정상적으로 적재되었는지를 확인하기 떄문에 소요 시간이 발생한다.

**acks=all or acks=-1**

<img width="306" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/6b0a7fe7-cff5-43f9-922b-68cc44383ee9">

프로듀서는 보낸 데이터가 리더 파티션과 팔로워 파티션에 모두 정상적으로 적재되었는지를 확인한다.
가장 속도가 느리지만 팔로우 파티션에 데이터가 정상 적재되었는지 기다리기 때문에 일부 브로커에 장애가 발생하더라도 프로듀서는 안전하게 데이터를 전송하고 저장할 수 있음을 보장한다.
acks를 all로 설정할 경우에는 토픽 단위로 설정 가능한 min.insync.replicas 옵션값에 따라 데이터 안정성이 달라진다. (브로커 개수만큼의 팔로워 파티션을 모두 확인하는 것이 아니다.)
예를 들어 min.insync.replicas가 2이고 복제가 3인 경우에 리더 파티션 확인, 팔로워 파티션 하나 확인한다.

일반적으로 min.insync.replicas을 2로 설정해도 충분하다. 참고로 옵션값을 1로 설정하면 acks를 1로 했을 때와 동일한 동작을 한다. 

-1로 설정하면 데이터 처리량이 큰 경우 속도가 굉장히 떨어지므로 해당 옵션을 사용하면 안된다.

- acks 옵션은 프로듀서 옵션이고, min.insync.replicas 옵션은 토픽 옵션

## 커스텀 파티셔너 프로듀서 애플리케이션

프로듀서 사용환경에 따라 특정 데이터를 가지는 레코드를 특정 파티션으로 보내야 할 때가 있다.
에를 들어, Pangyo라는 값을 가진 메시지 키가 0번 파티션으로 들어가야 한다고 가정하자.
기본 설정 파티셔너를 사용할 경우 메시지 키의 해시값을 파티션에 매칭하여 데이터를 전송하므로 어느 파티션에 들어가는지 알 수 없다.
이때 Partitioner 인터페이스를 사용하여 사용자 정의 파티셔너를 생성하면 Pangyo라는 값을 가진 메시지 키에 대해서 무조건 파티션 0번으로 지정하도록 설정할 수 있다.
이렇게 지정할 경우 토픽의 파티션 개수가 변경되더라도 Pangyo라는 메시지 키를 가진 데이터는 파티션 0번에 적재된다.

```kotlin
class CustomPartitioner : Partitioner {
    override fun configure(configs: MutableMap<String, *>?) {}

    override fun close() {}

    override fun partition(
        topic: String?,
        key: Any?,
        keyBytes: ByteArray?,
        value: Any?,
        valueBytes: ByteArray?,
        cluster: Cluster?,
    ): Int {
        if (keyBytes == null) throw InvalidRecordException("Need message key")

        if (key == "Pangyo") return 0

        val partitions = cluster!!.partitionsForTopic(topic)
        val numPartitions = partitions.size
        return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions
    }
}

configs[ProducerConfig.PARTITIONER_CLASS_CONFIG] = CustomPartitioner::class.java
```

## 레코드의 전송 결과를 확인하는 프로듀서

KafkaProducer의 send() 메서드는 Future 객체를 반환한다.
이 객체는 RecordMetadata의 비동기 결과를 표현하는 것으로 ProducerRecord가 카프카 브로커에 정상적으로 적재되었는지에 대한 데이터가 포함되어 있다.
아래 코드와 같이 get() 메서드를 사용하면 프로듀서로 보낸 데이터 결과를 동기적으로 가져올 수 있다.

```kotlin
val metadata = producer.send(record).get()
```

**결과**

```text
[main] INFO ProducerWithSyncCallback - test-1@5
```

test라는 토픽에 데이터를 넣었고, 1번 파티션 5번 오프셋으로 데이터가 저장되었다.

**만약 ACKS 옵션을 0으로 설정하면?** 

```text
[main] INFO ProducerWithSyncCallback - test-1@-1
```

1번 파티션에 저장했지만 응답을 받지 않았기 때문에 오프셋값은 알 수 없다.

## 프로듀서의 안전한 종료

프로듀서를 안전하게 종료하기 위해서는 close() 메서드를 이용하여 어큐뮤레이터에 저장되어 있는 모든 데이터를 카프카 클러스터로 전송해야 한다.

```text
producer.close()
```

## Kafka Producer의 send() 호출 프로세스


<img width="775" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/4f19c5eb-0fc9-4dd6-8ac6-641bb8a4a4c2">

- Kafka Producer 전송은 Producer Client의 별도 Thread가 전송을 담당한다는 점에서 기본적으로 **Thread간 Async 전송**
- 즉 Producer Client의 Main Thread가 send() 호출하여 메시지 전송을 시작하지만 바로 전송되지 않으며 내부 Buffer에 메시지를 저장 후(배치 단위)에 별도의 Thread가 Kafka Broker에 실제 전송을 하는 방식
  - kafka-producer-network-thread

### 동기화 / 비동기화 전송

**동기화 방식**

Producer가 브로커로 부터 해당 메시지를 성공적으로 받았다는 Ack 메시지를 받은 후 다음 메시지를 전송한다.
- producer.send().get() 을 호출하여 브로커로부터 Ack 메시지를 받을 때까지 대기하는 방식
- Future 객체의 get()을 호출하여 브로커로부터 메시지 Ack 응답을 받을 때 까지 Main Thread가 대기

```kotlin
val future: Future<RecordMetaData> = producer.send()
val recordMetadata = future.get()
```

```text
* Since the send call is asynchronous it returns a {@link java.util.concurrent.Future Future} for the
* {@link RecordMetadata} that will be assigned to this record. Invoking {@link java.util.concurrent.Future#get()
* get()} on this future will block until the associated request completes and then return the metadata for the record
* or throw any exception that occurred while sending the record.
```

**비동기화 방식**

Producer가 브로커로 부터 해당 메시지를 성공적으로 받았다는 Ack 메시지를 기다리지 않고 전송한다.
- 브로커로부터 Ack 메시지를 비동기로 Producer가 받기 위해서 Callback을 적용
- send() 메소드 호출 시에 callback 객체를 인자로 입력하여 Ack 메시지를 Producer가 전달 받을 수 있다.

<img width="814" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/c73ac8e7-e04e-4ccd-9559-8fb524f3bc56">

### Callback의 이해

콜백은 다른 코드의 인수로서 넘겨주는 실행 가능한 코드이며, 콜백을 넘겨받는 코드는 이 콜백을 필요에 따라 즉시 실행할 수도 있고, 아니면 나중에 실행할 수도 있다.
즉, Callback은 다른 함수의 인자로서 전달된 후에 특정 이벤트가 발생 시 해당 함수에서 다시 호출된다.

일반적으로 자바에서는

1. 콜백을 인터페이스로 구성, 호출되어질 메서드를 선언
2. 해당 콜백을 구현하는 객체 생성 (즉, 호출 되어질 메소드를 구체적으로 구현)
3. 다른 함수의 인자로 해당 콜백을 인자로 전달
4. 해당 함수는 특정 이벤트 발생 시 콜백에 선언된 메소드를 호출

### 비동기 메시지 전송/재전송 이해 

<img width="669" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/c9a32bd6-8614-4958-a06e-77d3a2179120">

1. Main Thread는 실제 Send를 담당하는 Network Thread에게 메시지 뿐만 아니라 콜백 객체를 함께 전송
2. Network Thread는 콜백 객체를 가지고 있고, 메시지를 브로커 전송
3. 이후에 브로커가 메시지 1 Ack를 전송하면 콜백 객체에 결과를 담는다. (파티션 정보, 오프셋 정보, 예외 정보, ...)
4. 메인 스레드와 네트워크 스레드는 메모리 주소를 공유하기 떄문에 콜백 객체의 참조를 메인 스레드가 가져온다.

카프카 프로듀서는 재전송 매커니즘이 존재하는데 Ack가 오지 않거나 retryable한 exception이 오면 내부적으로 네트워크 스레드는 자체적으로 브로커에 재전송한다. (sync, async 상관 X)
- acks = 0 : 재전송 X
- acks = 1, -1(all) : 재전송 O

```kotlin
producer.send(record, object: Callback {
    @Override
    fun onCompletion(metadata: RecordMetadata, exception: Exception) {
    ...
    }
}
```

> 실직적으로 onCompletion을 호출하는 대상은 Network Thread 

## acks all

- Producer는 리더 브로커가 메시지 A를 정상적으로 받은 뒤 min.insync.replicas 개수 만큼의 Replicator에 복제를 수행한 뒤에 보내는 Ack 메시지를 받은 후 다음 메시지인 메시지 B를 전송한다.

> min.insync.replicas : 최소 리플리케이션 팩터를 지정하는 옵션
>
> 만약 replication.factor=3인데, 하나의 팩터가 죽더라도 min.insync.replicas는 2로 설정되어 있기 때문에 문제가 없으나, 하나가 더 죽는다면 프로듀서는 에러(NOT_ENOUGH_REPLICAS)를 받게된다.
> 일반적으로 replication.factor=3, min.insync.replicas=2를 권장한다

<img width="801" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/bf2d9a12-e3fe-42f6-9836-484ae15672a8">

## Producer 메시지 배치 전송 내부 매커니즘 - Record Batch와 Record Accumulator 이해

<img width="775" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/ae430ede-e5d0-47fc-9514-4138abf55c61">

- Serialize -> Partitioning -> Compression(선택) -> Record Accumulator 저장 -> Sender에서 별도의 Thread가 브로커로 메시지 전송

### ProducerRecord

Record = Message = Event

<img width="261" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/09f3426e-ba3c-4683-b008-f5407d170b99">

<img width="761" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/108cd51e-cb44-4ec0-9792-1b1f7bcd5137">

KafkaProducer 객체의 send() 메서드는 하나의 ProducerRecord를 입력하지만 바로 전송 되지 않고 내부 메모리에서 단일 메시지를 토픽 파티션에 따라 Record Batch 단위로 묶인 뒤 전송된다.

메시지들은 Producer Client의 내부 메모리에 여러 개의 Batch들로 buffer.memory 설정 사이즈 만큼 보관될 수 있으며 여러 개의 Batch들로 한꺼번에 전송될 수 있다.

> send(...).get()을 통해서 동기 방식으로 전달한다는 것은 sender의 쓰레드가 응답을 받을 때까지 묶는것
> 
> 개별 메시지 별로 응답을 받을 때까지 block이 되는 방식으로는 메시지 배치 처리가 불가. 전송은 배치레벨이지만 배치에 메시지는 단 1개
> (즉, sync 방식의 성능 영향에는 blocking, batch 두 가지 이유가 존재한다)

### Record Batch와 Record Accumulator 이해 

<img width="816" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/7198349c-b954-4e1f-8e74-047500c39846">

- Record Accumulator는 Partitioner에 의해서 메시지 배치가 전송이 될 토픽과 Partition에 따라 저장되는 KafkaProducer 메모리 영역이다.
- Sender Thread는 Record Accumulator에 누적된 메시지 배치를 꺼내서 브로커로 전송한다.
- KafkaProducer의 Main Thread는 send() 메소드를 호출하고 Record Accumulaotr에 데이터 저장하고 Sender Thread는 별개로 데이터를 브로커로 전송한다.

### linger.ms와 batch.size 파라미터

<img width="797" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/f948cfb9-1671-4f94-b57f-0faa03da0db6">

- linger.ms를 통해 Sender Thread가 메시지를 다이렉트로 가져가지 않고 배치에 메시지가 쌓일 수 있도록 시간 여유를 주는 옵션
- Sender Thread는 기본적으로 전송할 준비가 되어 있으면 Record Accumulator에서 1개의 배치를 가져갈수도, 여러 개의 배치를 가져 갈 수도 있다. 또한 배치에 메시지가 다 차지 않아도 가져갈 수 있다.
- linger.ms를 0보다 크게 설정하여 Sender Thread가 하나의 Record Batch를 가져갈 때 일정 시간 대기하여 Record Batch에 메시지를 보다 많이 채울 수 있도록 적용

<img width="789" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/f9be1d48-5d91-4257-80ed-24ba003fb351">

- Record Accumulator에서 목적지(Topic A - Partition 1)를 미리 설정하여 메시지를 배치 단위로 만든다. 즉, Sender Thread에서 재조립하지 않는다.
- max.in.flight.requests.per.connection 를 통해서 하나의 커넥션에서 여러 개의 배치를 브로커로 전송할 수 있다.

**linger.ms와 batch.size 파라미터 고찰**

- linger.ms를 반드시 0보다 크게 설정할 필요는 없다.
  - linger.ms가 0이라고 배치가 안차는게 아니다. 
  - Producer와 Broker간의 전송이 매우 빠르고 Producer에서 메시지를 적절한 Record Accumulator에 누적된다면 linger.ms가 0이 되어도 무방
  - 전반적인 Producer와 Broker 간의 전송이 느리다면 linger.ms를 높여서 메시지가 배치로 적용될 수 있는 확률을 높이는 시도를 해볼만 하다.
- linger.ms는 보통 20ms 이하로 설정 권장

```kotlin
props[ProducerConfig.BOOTSTRAP_SERVERS_CONFIG] = bootstrapServers
props[ProducerConfig.BATCH_SIZE_CONFIG] = 16384
props[ProducerConfig.LINGER_MS_CONFIG] = 1
props[ProducerConfig.SEND_BUFFER_CONFIG] = 128 * 1024
props[ProducerConfig.MAX_REQUEST_SIZE_CONFIG] = 1 * 1024 * 1024
props[ProducerConfig.RECONNECT_BACKOFF_MS_CONFIG] = 50
props[ProducerConfig.MAX_BLOCK_MS_CONFIG] = 60 * 1000
props[ProducerConfig.BUFFER_MEMORY_CONFIG] = 32 * 1024 * 1024
props[ProducerConfig.COMPRESSION_TYPE_CONFIG] = "none"
props[ProducerConfig.RETRIES_CONFIG] = 3
props[ProducerConfig.ACKS_CONFIG] = "all"
props[ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG] = 30 * 1000
props[ProducerConfig.INTERCEPTOR_CLASSES_CONFIG] = ProducerInterceptor::class.jvmName
```

- max.request.size : 프로듀서가 브로커에 한 번 요청할 때 보낼 수 있는 최대 크기

## Producer의 전송/재전송 내부 매커니즘 및 재전송 동작 관련 주요 파라미터의 이해 

<img width="572" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/54cf8c57-f4a9-49ef-9bd4-5545f66881f9">

- delivery.timeout.ms : Sender Thread가 메시지를 전송하다가 응답이 없거나 오류가 발생하면 재전송하는데 언제까지 재전송할지 결정하는 파라미터
- 만약에 Record Accumulator가 가득찬 경우에 send()를 호출하더라도 max.block.ms만큼 기다리게된다. 
  - 만약에 기다려도 못넣는 경우에 Timeout Exception이 발생한다.

<img width="839" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/fa433131-0508-408d-a820-98e50c67d55a">

Sender Thread가 브로커로 메시지를 전송하는데 만약에 request.timeout.ms 만큼 기다려도 ack가 오지않는 경우에 retry.backoff.ms 뒤에 재전송을 시도한다.
재전송 시도할 때 delivery.timeout.ms가 지난 경우에는 재전송하지 않고 전송 실패로 간주한다.

- **delivery.timeout.ms >= linger.ms + request.timeout.ms**
  - 해당 기준을 만족하지 못하면 애플리케이션 실행이 안된다.
  - `Caused by: org.apache.kafka.common.config.ConfigException: delivery.timeout.ms should be equal to or larger than linger.ms + request.timeout.ms`

<img width="426" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/6e45daa5-f925-44c0-80e1-3f7a483185a5">

- retries 파라미터를 통해 재전송 횟수를 지정할 수 있지만 결과적으로 delivery.timeout.ms가 되면 재전송을 중지한다.
- 일반적으로 retries 무한대값으로 설정하고 delivery.timeout.ms(기본 120000, 2분)를 조정하는 것을 권장한다.

**retries=10, retry.backoff.ms=30, request.timeout.ms=10000ms**

- 메시지를 전송했는데, 10000ms(request.timeout.ms) 만큼 기다렸는데 에러 또는 응답이 없다면 30ms(retry.backoff.ms)뒤에 재전송한다.
- 이렇게 10회(retries)를 반복했는데 전송 실패시 재전송하지 않는다.

## max.in.flight.requests.per.connection 이해

<img width="803" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/b29e5242-7116-449c-9d2e-fab7c0245f53">

- 브로커 서버의 응닶없이 Producer의 Sender Thread가 한번에 보낼 수 있는 메시지 배치의 개수 (Default 5)
- Kafka Producer의 메시지 전송 단위는 Batch
- 비동기 전송 시 브로커의 응답없이 한꺼번에 보낼 수 있는 Batch의 개수는 max.in.flight.reqeust.per.connection에 따른다.

### Producer 메시지 전송 순서와 Broker 메시지 저장 순서 고찰

<img width="792" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/7c85ade6-1dbd-46ff-b383-3301519af9f5">

- B0가 B1보다 먼저 Producer에서 생성된 메시지 배치
- max.in.flight.request.per.connection=2(>1)에서 B0, B1 2개의 배치 메시지를 전송 시 B1은 성공적으로 기록 되었으나 B0의 경우 Write되지 않고 Ack 전송이 되지 않은 Failure 상황이 된 경우 Producer는 B0를 재전송하여 성공적으로 기록되며 Producer는 원래 메시지 순서와는 다르게 Broker에 저장 될 수 있다.
- enable.idempotence=true 설정을 통해서 max.in.flight.request.per.connection이 1보다 큰 경우 발생할 수 있는 메시지 순서 이슈를 해결할 수 있다.

## 최대 한번 전송, 적어도 한번 전송, 정확히 한번 전송 이해

- 최대 한번 전송(at most once): acks = 0, 중복허용X
  - 메시지가 소실될 수는 있지만 중복 전송X
- 적어도 한번 전송(at least once): acks = 1, all, retry > 0, 중복허용
  - Producer는 브로커로부터 ACK를 받은 다음에 다음 메시지를 전송한다.
  - 메시지 소실은 없지만 중복 전송을 할 수 있음
- 정확히 한번 전송(exactly once)
  - 중복 없이 전송(멱등성, Idempotence): Producer의 메시지 전송 retry시 중복 제거 
  - Transaction 기반 전송: 트랜잭션 기반 전송이 보장되려면 Idempotence이어야 한다. Consumer -> Process -> Producer(주로 Kafka Streams)에 주로 사용되는 트랜잭션 기반 처리

## Idempotence(멱등성) 기반 중복 없이 전송 이해

> default 설정이 멱등성을 보장한다

- Producer는 브로커로부터 ACK를 받은 다음에 다음 메시지를 전송하되, Producer ID와 메시지 Sequence를 Header에 가지고 있어서 브로커에서 메시지가 중볼될 경우 이를 메시지 로그에 기록하지 않는다.
- 메시지 Sequence는 메시지의 고유 Sequence 번호로 0부터 시작하여 순차적으로 증가한다. Producer ID는 Producer가 기동시마다 새롭게 생성
- 브로커에서 메시지 Sequence가 중복 될 경우 리를 메시지 로그에 기록하지 않고 Ack만 전송
- 브로커는 Producer가 보낸 메시지의 Sequence가 브로커가 가지고 있는 메시지의 Sequence보다 1만큼 큰 경우에만 브로커에 저장

<img width="366" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/d791a51c-76bb-40bf-8b8b-e906ed880879">

- 메시지 A가 정상적으로 브로커에 기록되고 Ack 전송 (브로커에 메시지 A 저장, 프로듀서는 Ack를 기다린 후 메시지 B 전송)
- 메시지 B가 정상적으로 브로커에 기록되었지만 네트워크 장애등으로 Ack를 Producer에게 보내지 못함. (메시지 B는 메시지 시퀀스 1로 브로커에 저장)
- 메시지 B의 Ack를 받지 못한 프로듀서는 메시지 B를 다시 보낸다.
  - 메시지 B는 재전송되었지만 브로커는 Seq 1인 메시지가 이미 저장되어서 해당 메시지를 메시지 로그에 저장하지 않고 Ack만 보낸다.

### Idempotence를 위한 Producer 설정

- enable.idempotence=true
- acks=all
- retries는 0보다 큰 값
- max.in.flight.requests.per.connection은 1에서 5사이 값
  - Idempotence를 유지하기 위해서 내부 캐시가 5까지만 수용할 수 있음
- Idempotence를 적용하면 성능이 감소(최대 20%)할 수 있지만 기본적으로 적용을 권장한다.

### Idempotence 기반에서 메시지 전송 순서 유지


- Idempotence 기반에서 max.in.flight.requests.per.connection 만큼 여러 개의 배치들이 브로커에 전송
- 브로커는 메시지 배치를 처리시 write된 배치의 마지막 메시지 sequence+1이 아닌 배치 메시지가 올 경우 OutOfOrderSequenceException을 생성하여 프로듀서에 오류로 전달한다.

<img width="730" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/c4077052-000f-4c64-a8ae-01c2dde7d1f0">

- B0(0~10) write가 성공하여 해당 배치의 마지막 시퀀스가 10이라고 가정
- B1(11~20) write는 실패
- B2를 write 시도 시 B0의 마지막 시퀀스 + 1(11)이 B2의 첫번째 메시지의 시퀀스가 아니기 때문에 에러 발생
  - 프로듀서는 에러를 받고 재전송 로직을 수행, B0을 재전송하더라도 적재하지 않고 ACK만 전송

**유의사항**

- Kafka 3.0 버전 부터는 Producer의 기본 설정이 Idempotence
- 하지만 기본 설정중에 enable.idempotence=true를 제외하고 다른 파라미터들을 잘못 설정하면(예를 들어 acks=1) Producer는 정상적으로 메시지를 보내지만 Idempotence로는 동작X
- 명시적으로 enable.idempotence=true를 설정한 뒤 다른 파라미터들을 잘못 설정하면 Config 오류가 발생하면서 프로듀서가 기동되지 않는다.

## 커스텀 파티셔너

디폴트 파티셔너를 사용하면 메시지의 키값이 존재하면 키값을 해싱하여 파티션 별로 균일하게 파티셔너를 선택한다. (동일한 키라면 항상 동일한 파티션에 적재된다.)
키가 없다면 sticky partitioning 전략을 사용한다.

```java
public class DefaultPartitioner implements Partitioner {

    ...

    /**
     * Compute the partition for the given record.
     *
     * @param topic The topic name
     * @param numPartitions The number of partitions of the given {@code topic}
     * @param key The key to partition on (or null if no key)
     * @param keyBytes serialized key to partition on (or null if no key)
     * @param value The value to partition on or null
     * @param valueBytes serialized value to partition on or null
     * @param cluster The current cluster metadata
     */
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster,
                         int numPartitions) {
        if (keyBytes == null) {
            return stickyPartitionCache.partition(topic, cluster);
        }
        // hash the keyBytes to choose a partition
        return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
    }
  ...
}
```
- key : 원본 키값
- keyBytes : 직렬화된 키값
