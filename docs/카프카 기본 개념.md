# 카프카 기본 개념

## 오픈소스 아파치 카프카 생태계

<img width="616" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/760e5b94-b433-4162-95ab-4bc7ccd8a00c">

- 토픽에 저장된 데이터를 stateful, stateless 하게 데이터를 처리해서 다시 토픽에 넣고 싶은 경우에는 카프카 스트림즈라는 라이브러리를 이용할 수 있다.
- 소스 커넥트는 프로듀스 역할을 하고, 싱크 커넥트는 컨슈머 역할을 한다.
  - 소스 커넥트는 DB나 소스 애플리케이션에서 데이터를 가져와서 토픽에 데이터를 넣는 역할을 한다.
  - 싱크 커넥트는 타겟 애플리케이션으로 데이터를 보낸다.
- 커넥트가 아닌 프로듀서나 컨슈머로 개발하지 않는 이유는? 
  - 클러스터로 운영한다는 점이 다르고, 템플릿 형태로 반복적으로 여러번 생성할 수 있다.

애플리케이션을 운영할 때 프로듀서, 컨슈머, 소스 커넥트, 싱크 커넥트, 스트림즈를 가장 많이 사용한다.

## 카프카 브로커와 클러스터

카프카 브로커는 프로듀서로 데이터를 보내고 컨슈머로 데이터를 가져올 때 반드시 통신하게되는 프로세스이다.

### 카프카 브로커

카프카 클러스터는 여러 개의 브로커로 이뤄지는데, 하나하나의 브로커는 서버나 인스턴스에서 동작된다.
카프카 브로커 서버 1대로도 기본 기능이 실행되지만 데이터를 안전하게 보관하고 처리하기 위해 3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 운영한다.

#### 브로커의 역할

**컨트롤러**

클러스터의 다수 브로커 중 한 대가 컨트롤러의 역할을 한다.
컨트롤러는 다른 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배한다.
카프카는 지속적으로 데이터를 처리해야 하므로 브로커의 상태가 비정상이라면 빠르게 클러스터에서 빼내는 것이 중요하다. 만약 컨트롤러 역할을 하는 브로커에 장애가 생기면 다른 브로커가 컨트롤러 역할을 한다.

> 카프카 브로커는 리더, 팔로워라는 두 가지 유형의 브로커가 존재하는데, 리더 브로커는 해당 파티션에 대한 모든 읽기/쓰기 연산을 처리하며, 팔로워 브로커는 리더의 데이터를 복제하여 데이터의 안정성을 확보한다.
> 
> 만약 리더 브로커가 클러스터에서 빠지거나 장애가 발생하게 되면, 해당 파티션에 대한 읽기/쓰기 연산 처리가 불가능해지므로 이러한 상황에서 컨트롤러는 클러스터 내의 다른 건강한 브로커 중에서 새로운 리더를 선출하고, 이를 클러스터의 메타데이터에 업데이트한다.

**데이터 삭제**

카프카는 다른 메시징 플랫폼과 다르게 컨슈머가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않는다. 또한, 컨슈머나 프로듀서가 데이터 삭제를 요청할 수도 없다.
오직 브로커만이 데이터를 삭제할 수 있다. 데이터 삭제는 파일 단위로 이루어지는데, 이 단위를 로그 세그먼트라고 부른다. 해당 세그먼트에는 다수의 데이터가 들어 있기 때문에 일반적인 DB처럼 특정 데이터를 선별해서 삭제할 수 없다.

**컨슈머 오프셋 저장**

컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋한다.

> 커밋한 오프셋은 __consumer_offsets 토픽에 저장한다. 여기에 저장된 오프셋을 토대로 컨슈머 그룹은 다음 레코드를 가져가서 처리한다.

**코디네이터**

컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할을 한다. 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 동작하는 컨슈머로 할당하여 끊임없이 데이터가 처리되도록 도와준다. (파티션을 새로운 컨뮤서를 재할당하는 과정을 리밸런스라고 한다.)

> 기본적으로 각각의 파티션은 컨슈머와 1대1 매핑된다.

**데이터의 저장**

카프카를 실행할 때 config/server.properties의 log.dir 옵션에 정의한 디렉토리에 데이터를 저장한다.  
토픽 이름과 파티션 번호의 조합으로 하위 디렉토리를 생성하여 데이터를 저장한다. 

> 브로커에 데이터가 저장될 때 파일 시스템에 데이터를 저장한다. 즉 파일 시스템의 위치를 정하는 것

- xxx.log : 메시지와 메타데이터를 저장한 파일 -> 한 파일에 모든 데이터를 저장하는 것이 아닌 바이트 단위(기본 1GB) 혹은 시간 단위(기본 7일)로 나눠서 저장된다.
  - 쓰기가 일어나고 있는 세그먼트(log 파일)를 active 세그먼트라고 부른다.
  - active 세그먼트는 브로커의 삭제 대상에 포함되지 않는다.
  - 엑티브 세그먼트가 아닌 세그먼트는 retention 옵션에 따라 삭제 대상으로 지정된다.
- xxx.index : 메시지의 오프셋을 인덱싱한 정보를 담은 파일
- xxx.timeindex : 메시지에 포함된 timestamp값을 기준으로 인덱싱한 정보를 담은 파일

**복제(Replication)**

<img width="444" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/3351fb10-d5b0-4718-9cc3-fea0d4ce57fe">

데이터 복제(replication)는 카프카를 장애 허용 시스템(fault tolerant system)으로 동작하도록 하는 원동력이다.
복제의 이유는 클러스터로 묶인 브로커 중 일부에 장애가 발생하더라도 데이터를 유실하지 않고 안전하게 사용하기 위함이다.

카프카의 데이터 복제는 파티션 단위로 이루어진다. 토픽을 생성할 때 파티션의 복제 개수 (replication factor)도 같이 설정되는데 직접 옵션을 선택하지 않으면 브로커에 설정된 옵션 값을 따라간다.
복제 개수의 최솟값은 1(복제 X)이고 최댓값은 브로커 개수만큼 설정하여 사용할 수 있다.
(보통 상용 환경에서는 2~3으로 설정한다. 위 그림은 replication factor 가 3인 상황)

팔로워 파티션은 리더 파티션에 데이터가 추가됨을 확인하는데, offset을 통해서 확인한다. 
예를 들어 리더 파티션의 offset이 (0, 1, 2)인데 팔로워 파티션의 offset이 (0)이라면 1, 2가 비어있기 때문에 팔로워 파티션의 브로커는 리더 파티션으로 부터 데이터를 복제한다.

### 세그먼트와 삭제 주기

<img width="714" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/ec3a3bce-98a2-47f3-80d3-f1077ca18991">

**cleanup.policy=delete**

- retention.ms : 세그먼트를 보유할 최대 기간. (기본 7일)
  - 주말에 대응이 어려울 수 있기 때문에 일반적으로 3일을 유지한다.
- retention.bytes : 파티션당 로그 적재 바이트 값. (기본 -1, 지정하지 않음)
- log.retention.check.interval.ms : 브로커가 세그먼트가 삭제 영역에 들어왔는지 확인하는 간격 (기본 5분)

카프카에서 데이터는 세그먼트 단위로 삭제가 발생하기 때문에 로그 단위(레코드 단위)로 개별 삭제는 불가능하다. 
또한, 로그(레코드)의 메시지 키, 메시지 값, 오프셋, 헤더 등 이미 적재된 데이터에 대해서 수정이 불가능하기 때문에 데이터를 적재할 때(프로듀서) 또는 데이터를 사용할 때(컨슈머) 애플리케이션 레벨에서 데이터를 검증하는 것이 좋다.

**cleanup.policy=compact**

<img width="687" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/7f2980c2-0aef-4438-b331-4a67d8076013">

clean 정책은 액티브 세그먼트가 아닌 세그먼트를 기준으로 특정 세그먼트 로그를 삭제하는 정책이고, compact 정책은 일반적으로 생각하는 zip과 같은 압축과는 다른 개념이다. 

여기서 압축이란 메시지 키 별로 해당 메시지 키의 레코드 중 오래된 데이터를 삭제하는 정책을 뜻한다. 그렇기 때문에 삭제 정책돠 다르게 일부 레코드만 삭제가 될 수 있다.
압축은 액티브 세그먼트를 제외한 데이터가 대상이다. 

<img width="750" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/475304b5-06cc-4fc5-aa92-00f6334a492d">

압축이 실행될 때 영역에 따라 다르게 진행된다.

- 테일 영역 : 압축 정책에 의해 압축이 완료된 레코드들. 클린 로그 라고도 부른다. (중복 메시지 키가 없다.)
- 헤드 영역 : 압축 정책이 되기 전 레코드들. 더티 로그 라고도 부른다. (중복 메시지 키가 있다.)

<img width="729" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/b0537b53-bdcf-46a5-81da-865647cf841b">

클린 레코드의 개수와 더티 레코드의 개수에 따라서 압축 시작을 실행하는데, 이를 min.cleanable.dirty.ratio 옵션값에 따른다.
위 예시처럼 0.5로 설정한다면 테일 영역의 레코드 개수가 헤드 영역의 레코드 개수와 동일할 경우 압축이 실행된다.

만약 0.9와 같이 크게 설정하면 한번 압축을 할 때 많은 데이터가 줄어들므로 압축 효과가 좋다. 그러나 0.9 비율이 될 때 까지 용량을 차지하므로 용량 효율이 좋지 않다.
반면 0.1과 같이 작게 설정하면 압축이 자주 일어나서 가장 최신 데이터만 유지할 수 있지만 압축이 자주 발생하기 때문에 브로커에 부담을 줄 수 있다.

### 카프카 클러스토아 주키퍼

주키퍼는 카프카 클러스터를 운영하기 위해 반드시 필요한 애플리케이션이다. 

> 카프카 클러스터를 운영할 때 2.x 버전까지는 주키퍼가 반드시 필요했지만 3.x 버전 부터는 없어도 된다. (하지만 아직까지는 완벽하게 대체 불가)

<img width="436" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/cd6b48c0-354b-4f69-b633-2f887189deda">

### ISR(In-Sync-Replicas)

<img width="457" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/30e8e4b6-d516-4f2b-adce-ba22c23af92d">

ISR은 리더 파티션과 팔로워 파티션이 모두 싱크가 된 상태를 뜻한다.

리더 파티션의 데이터를 팔로워 파티션이 모두 복제하지 못한 상황에서 장애가 발생한다면 기존의 데이터 복제가 덜 된 팔로워 파티션이 리더로 승격하여 데이터 유실이 발생할 수 있다.
이때 유실이 발생하더라도 서비스를 중단하지 않고 지속적으로 토픽을 사용하고 싶다면 ISR이 아닌 팔로워 파티션을 리더로 선출하도록 설정할 수 있다.

- unclean.leader.election.enable : true -> 유실을 감수함. 복제가 안된 팔로워 파티션을 리더로 승급
- unclean.leader.election.enable : false -> 유실을 감수하지 않음. 해당 브로커가 복구될 때까지 중단

서비스 특성에 따라서 옵션을 달리한다.

### 토픽과 파티션

<img width="572" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/044027dc-0e66-481e-aac7-a4ee303dad31">

토픽은 카프카에서 데이터를 구분하기 위해 사용하는 단위이다. 토픽은 1개 이상의 파티션을 소유하고 있다.

파티션에는 프로듀서가 보낸 데이터들이 들어가 저장되는데 이 데이터를 레코드라고 부른다.
파티션은 자료구조에서 접하는 큐와 비슷한 구조라고 생각하면 쉽다. FIFO 구조와 같이 먼저 들어간 레코느는 컨슈머가 먼저 가져가게 된다. (단, 큐처럼 pop하면 데이터가 사라지진 않는다.)

파티션의 레코드는 컨슈머가 가져가는 것과 별개로 관리되며, 이러한 특징 때문에 토픽의 레코드는 다양한 목적을 가진 여러 컨슈머 그룹들이 토픽의 데이터를 여러번 가져갈 수 있다.

**토픽 생성시 파티션이 배치되는 방법**

<img width="724" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/11740b10-68ee-4928-98d6-2b5c36e8ac54">

파티션이 5개인 토픽을 생성했을 경우 그림과 같이 0번 브로커부터 시작하여 round-robin 방식으로 **리더 파티션**들이 생성된다.
카프카 클라이언트는 리더 파티션이 있는 브로커와 통신하여 데이터를 주고 받으므로 여러 브로커에 골고루 네트워크 통신을 하게 된다. 
이를 통해, 데이터가 특정 서버(브로커)와 통신이 집중되는 hot spot 현상을 막고 선형 확장을 하여 데이터가 많아지더라도 자연스럽게 대응할 수 있다.

<img width="706" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/d7ccd48c-b842-4942-8487-e25adbe46f32">

- 위 상황은 replication factor가 3이고 브로커가 3인 상황

> 만약 특정 브로커에 파티션이 쏠리는 경우 kafka-reassign-partitions.sh 명령으로 파티션을 재분배할 수 있다.

> 카프카 토픽을 설정할 때 파티션 개수를 설정할 수 있지만 따로 설정하지 않으면 브로커에 설정된 기본 설정값으로 설정된다.

**파티션 개수와 컨슈머 개수의 처리량**

<img width="489" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/5863943d-0d89-4da5-9caa-d1748f786eb8">

파티션은 카프카 병렬처리의 핵심으로써 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭된다.
컨슈머의 처리량이 한정된 상황에서 많은 레코드를 병렬로 처리하는 가장 좋은 방법은 컨슈머의 개수를 늘려 스케일 아웃하는 것이다.
컨슈머 개수를 늘림과 동시에 파티션 개수도 늘리면 처리량이 증가하는 효과를 볼 수 있다.

> 기본적으로 컨슈머와 파티션의 관계는 1대1 관계이며, 파티션은 최대 1개의 컨슈머와 매칭될 수 있다.

만약 프로듀서가 초당 10개의 데이터를 프로듀싱하는데 초당 1개를 처리하는 컨슈머가 1개 있다면 데이터 처리에 지연이 발생하고 이를 **컨슈머렉** 이라고 부른다.

**파티션 개수를 줄이는 것은 불가능**

<img width="624" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/a69f25a5-0eb3-48e3-8341-d89035bcf4d5">

카프카에서 파티션 개수를 줄이는 것은 지원하지 않는다. 그러므로 파티션을 늘리는 작업을 할 때는 신중히 파티션 개수를 정해야 한다. (한번 늘리면 줄이는 것은 불가능하기 때문에 토픽을 삭제하고 재생성하는 방법 외에는 없기 때문)

> 카프카에서는 파티션의 데이터를 세그먼트(디렉토리에 저장)로 저장하고 있으며 만에 하나 지원을 한다고 하더라도 여러 브로커에 저장된 데이터를 취합하고 정렬해야하는 복잡한 과정을 거쳐야 하기 때문에 클러스터에 큰 영향이 가게 된다.

### 레코드 

<img width="301" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/6a2c06ec-55d3-4e77-a0f1-317caad44866">

레코드는 타임스탬프, 헤더, 메시지 키, 메시지 값, 오프셋으로 구성되어 있다. 프로듀서가 생성한 레코드가 브로커로 전송되면 오프셋과 타임스탬프가 지정되어 저장된다.
브로커에 한번 적재된 레코드는 수정할 수 없고 로그 리텐션 기간 또는 용량에 따라서만 삭제된다. 

**타임스탬프**

스트림 프로세싱에서 활요하기 위한 시간을 저장하는 용도로 사용된다. 카프카 0.10.0.0 이후 버전부터 추가된 타임스탬프는 Unix timestamp가 포함되어 프로듀서에서 따로 설정하지 않으면 기본값으로 ProducerRecord 셍상 시간(CreateTime)이 들어간다.
또는 브로커 적재시간(LogAppendTime)으로 설정할 수도 있다. 해당 옵션은 토픽 단위로 설정 가능하며 message.timestamp.type을 사용한다.

**오프셋**

오프셋은 프로듀서가 생성한 레코드에는 존재하지 않는다. 프로듀서가 전송한 레코드가 브로커에 적재될 때 오프셋이 지정된다.
오프셋은 0부터 시작되고 1씩 증가한다. 컨슈머는 오프셋을 기반으로 처리가 완료된 데이터와 앞으로 처리해야할 데이터를 구분한다.

> 각 메시지는 파티션별로 고유한 오프셋을 가지므로 컨슈머에서 중복 처리를 방지하기 위한 목적으로도 사용한다.

**헤더**

key/value 데이터를 추가할 수 있으며 레코드의 스키마 버전이나 포맷과 같이 데이터 프로세싱에 참고할만한 정보를 담아서 사용할 수 있다. (참고용 데이터)

**메시지 키**

메시지 키는 처리하고자 하는 메시지 값의 분류하기 위한 용도로 사용되며, 이를 파티셔닝이라고 부른다.
파티셔닝에 사용하는 메시지 키는 파티셔너에 따라 토픽의 파티션 번호가 정해진다. 메시지 키는 필수 값이 아니며, 지정하지 않으면 null로 설정된다.

메시지 키가 null인 레코드는 특정 토픽의 파티션에 라운드 로빈으로 전달된다. null이 아닌 메시지 키는 해쉬값에 의해서 특정 파티션에 매핑되어 전달된다.

> 메시지 키를 통해 해당 레코드가 토픽의 어떤 파티션에 들어갈지 정해진다. 이때 정하는 주체가 파티셔너다.

**메시지 값**

레코드의 메시지 값은 실질적으로 처리할 데이터가 담기는 공간이다. 메시지 값의 포맷은 제네릭으로 사용자에 의해 지정된다.
다양한 타입이 가능하며 필요에 따라 사용자 지정 포맷으로 직렬화/역직렬화 클래스를 만들어 사용할 수도 있다.

> 브로커에 저장된 레코드의 값은 어떤 포맷으로 직렬화되어 저장되었는지 알 수 없기 때문에 컨슈머는 미리 역직렬화 포맷을 알고 있어야 한다.

### 유지보수하기 좋은 토픽 이름 정하기

**토픽 이름 제약 조건**

<img width="734" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/9a4ad6a0-f96b-4305-a66d-5c1b68b9b94c">

> 카프카는 토픽 이름 변경을 지원하지 않으므로 이름을 변경하기 위해서는 삭제 후 다시 생성하는 것 외에는 방법이 없다. 즉, 이름을 신중하게 정하자.

**토픽 작명의 템플릿과 예시**

<img width="434" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/ef8e297f-2be9-49d8-9d32-76a42f1be56f">

### 클라이언트 메타데이터와 카프카 클러스터(브로커) 통신

<img width="645" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/3fa9ac98-348f-4726-878d-6fde92853f10">

카프카 클라이언트는 통신하고자 하는 리더 파티션의 위치를 알기 위해 데이터를 주고(프로듀서) 받기(컨슈머) 전에 메타데이터(리더 파티션 위치이 어느 브로커에 존재하는지 정보가 존재)를 브로커로부터 전달받는다.
메타데이터는 다음과 같은 옵션을 통해 리프레쉬된다.

- metadata.max.age.ms : 메타데이터를 강제로 리프래시하는 간격, 기본 5분
- metadata.max.idle.ms : 프로듀서가 유효상태일 경우 메타데이터를 캐시에 유지하는 기간, 예를 들어 프로듀서가 특정 토픽으로 데이터를 보낸 이후 지정한 시간이 지나고 나면 강제로 메타데이터를 리프래시, 기본 5분

**클라이언트 메타데이터 이슈가 발생한 경우**

<img width="641" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/262c6fd1-5366-4402-b857-f350f1aacf2e">

카프카 클라이언트는 반드시 리더 파티션과 통신해야하는데 현재 메타데이터가 현재 파티션 상태에 맞게 리프래시되지 않은 상태에서 잘못된 브로커로 데이터를 요청하면 LEADER_NOT_AVALABLE 에러가 발생한다.

> 해당 에러가 자주 발생한다면 메타데이터 리프래시 간겨을 확인하고 클라이언트가 정상적인 메타데이터를 가지고 있는지 확인해야 하낟.



