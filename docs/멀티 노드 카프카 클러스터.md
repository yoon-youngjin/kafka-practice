# 멀티 노드 카프카 클러스터

- 분산시스템으로서 카프카의 성능과 가용성을 함께 향상 시킬 수 있도록 구성
- 스케일 아웃 기반으로 노드 증설을 통해 카프카의 메시지 전송과 읽기 성능을 (거의) 선형적으로 증가 시킬 수 있음
- 데이터 복제(Replication)을 통해 분산 시스템 기반에서 카프카의 최적 가용성을 보장

> 분산 시스템은 대량 데이터를 여러 노드간 분산 처리를 통해 빠르게 처리할 수 있는 큰 성능적 이점을 가지지만 안정성과 가용성 측면에서 상대적인 단점을 갖는다.

<img width="702" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/60d3e1e7-b33d-4e89-ba05-c5e80ab37c1e">

- active, passive 상태의 파티션을 복제해서 관리하다가 특정 브로커의 장애로 active 상태의 파티션이 동작을 못하면 다른 브로커의 passive 파티션을 active로 전환

`server_XX.properties`

```properties
...
broker.id=1 #1, 2, 3
...
listeners=PLAINTEXT://localhost:9092 #9092, 9093, 9094
...
log.dirs=/tmp/kafka-logs-01 #01, 02, 03
```

`zookeeper_m.properties`

```properties
...
dataDir=/tmp/zookeeper_m
```

## 멀티 브로커 카프카에서 여러 개의 파티션을 가지는 다중 복제 토픽 만들기 

```text
./kafka-topics --bootstrap-server localhost:9092 --create --topic m-brk-topic --partitions 3
```

- 9092, 9093, 9094 중 아무 브로커에 토픽을 생성해도 상관없다

<img width="688" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/acaff458-c102-4c16-85b0-092243c5ebbc">

- 파티션이 나누어져서 생성된 것을 확인할 수 있다.

**replication-factor 적용**

```text
./kafka-topics --bootstrap-server localhost:9092 --create --topic m-brk-topic-bb --partitions 3 --replication-factor 3
```

<img width="670" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/af5250ea-2817-41f6-9106-5935d66eb29e">

- 모든 브로커에 3개의 파티션이 존재한다

<img width="1021" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/f00b3958-447b-469c-8184-6fb778cad23b">

- 파티션 0은 3번 브로커에 리더 파티션이 존재하고 2번, 1번 브로커에 존재하는 파티션은 모두 팔로워이다.

## 카프카 Replication(복제)와 리더(Leader)/팔로워(Follower) 실습

- 카프카는 개별 노드의 장애를 대비하여 높은 가용성을 제공한다.
  - 가용성의 핵심은 **Replication**
- Replication은 토픽 생성 시 replication factor 설정값을 통해 구성
- Replication factor가 3이면 원본 파티션(리더 파티션)과 복제 파티션(팔로워 파티션)을 포함하여 모두 3개의 파티션을 가짐을 의미한다
- Replication factor의 개수는 브로커의 개수보다 클 수 없다.

- **Replication의 동작은 토픽내의 개별 파티션들을 대상으로 적용**
  - 토픽 자체에서 리더나 팔로워를 정하는게 아닌 개별 파티션을 대상으로 리더, 팔로워를 적용
- **Replication factor의 대상인 파티션들은 1개의 리더와 N개의 팔로워로 구성됨**

### 카프카 Replication의 리더와 팔로워

<img width="793" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/c80fa141-7e64-4edc-bd2a-bc69266796b7">

- 프로듀서와 컨슈머는 리더 파티션을 통해서 쓰기와 읽기를 수행한다
  - kafka 2.4부터느 컨슈머는 follower fetching이 가능

<img width="354" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/837a3c06-8713-4992-9ea8-2d8bb5563661">

- 파티션의 Replication은 리더에서 팔로워로만 이뤄진다.
  - 실제로는 팔로워가 리더 파티션으로부터 데이터를 읽어서 복제하는 흐름이다. (리더는 너무 바쁨)

<img width="771" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/d02a02e9-3432-4318-bfb7-b6fc883d3ab0">

- 파티션 리더를 관리하는 브로커는 Producer/Consumer의 읽기/쓰기를 관리함과 동시에 파티션 팔로우를 관리하는 브로커의 Replication도 관리
  - 팔로워 파티션이 리더 파티션을 제대로 복제하고 있는지도 파악한다는 의미 (ISR)
  - 각 팔로워 파티션에 모두 복제되었는지를 파악되면 ack를 반환 (acks=all인 경우)
  - 리더 브로커가 팔로워 브로커가 정상 동작하는지를 지속적으로 확인하는데 만약 특정 브로커가 정상 동작을 못한다면 isr에서 제외시킨다. 제외되면 이후에 팔로워 브로커 중 리더 브로커의 승격 대상에서 제외된다.

<img width="769" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/c51f7d2a-4667-4c23-9234-699a30fd6288">

위와 같은 단일 파티션인 경우에는 특정 브로커에 읽기, 쓰기 작업이 몰리기 때문에 부하를 야기할 수 있다.
이때, 멀티 파티션으로 구성하면 각 브로커에 리더 파티션이 나눠져서 구성되므로 부하를 줄일 수 있다.

## 멀티 브로커 환경에서 Producer의 bootstrap.servers 설정 이해

### Java Producer Clients에서 Multi Brokers 접속

- Producer는 bootstrap.server에 기술되어 있는 브로커들의 List를 기반으로 접속

```kotlin
val props = Properties()
props[ProducerConfig.BOOTSTRAP_SERVERS_CONFIG] = listOf("127.0.0.1:9092", "127.0.0.1:9093", "127.0.0.1:9094")
```

<img width="800" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/62fe56e4-8b36-489d-85ed-f2bacebaa622">

- 개별 브로커들은 토픽 파티션의 리더와 팔로워들의 메타 정보를 서로 공유하고, Producer는 초기 접속 시 해당 메타 정보를 가져와서 접속하려는 토픽의 파티션이 있는 브로커로 다시 접속한다.
  - 프로듀서 클라이언트가 접속할 때 토픽에 대한 메타 정보들은 모든 브로커 공용으로 가지고 있다. 
  - 리스트로 주어진 서버 리스트는 메타 정보를 가져오기 위한 리스트다. 
  - 따라서, 해당 정보들을 모두 공유하기 때문에 3대의 브로커가 클러스터를 구성중이라고 하더라도 1개의 서버 정보만 기입해도 된다.
    - 단, 해당 서버가 죽었을 때를 대비하여 여러 서버를 나열하는것이다.

즉, 브로커 3대로 운영 중인 상황에서 하나의 서버 주소만 기입하더라도 해당 브로커만 커넥션을 맺는것이 아닌 해당 브로커로부터 메타 정보를 가져와서 모든 브로커와 커넥션을 맺게된다. 

## 주키퍼(Zookeeper)와 컨트롤러(Controller) 브로커의 이해

### 주키퍼(Zookeeper) 개요

분산 시스템간의 정보(HearBeat 관리, Shutdown, ...)를 신속하게 공유하기 위한 코디네이션 시스템 

> 이전에는 각 노드들의 상태 정보를 노드들 중 마스터 노드에서 관리했다. (이렇게되면 마스터 노드의 부하가 너무 커진다는 단점)

<img width="249" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/973c6caf-97ec-4527-a23c-905fc6770c9a">

> Zookeeper는 Z Node(파일시스템과 유사) 기반에서 노드들의 상태를 관리하는 기본 스트럭처를 갖는다.

- 클러스터내 개별 노드의 중요한 상태 정보를 관리하며 분산 시스템에서 리더 노드(Controller)를 선출하는 역할등을 수행한다.
- 개별 노드간 상태 정보의 동기화를 위한 복잡한 Lock 관리 기능을 제공
- 간편한 디렉토리 구조 기반의 Z Node를 활용
- Z Node는 개별 노드(카프카 브로커)의 중요 정보를 담고 있다.
- 개별 노드들은 Zookeeper의 Z Node를 계속 모니터링하여 Z Node에 변경 발생 시 Watch Event가 트리거되어 변경 정보가 개별 노드들에 통보
- Zookeeper 자체의 클러스터링 기능 제공

### 카프카 클러스터에서 주키퍼의 역할

<img width="261" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/d6aae205-bd5a-4ee5-ac47-4fccf2107c92">

1. Controller Broker 선출(Election)
   
- 주키퍼에 접속하는 브로커 중에서 선착순으로 선출된다.
- 컨트롤러는 여러 브로커들에서 파티션 리더 선출을 수행한다.

2. 카프카 클러스터 내 브로커의 Membership 관리

- 클러스터의 브로커들의 List, 브로커 Join/Leave 관리 및 통보
  - 특정 브로커가 Leave되면 컨트롤러 브로커에 이를 알리고, 컨트롤러는 떠난 브로커의 리더 파티션을 남은 브로커 중에서 선출하게 된다.

3. TOPIC 정보

- 토픽의 파티션, replicas등의 정보를 갖는다.

### 주키퍼에서 Kafka Cluster 정보 관리

- 모든 카프카 브로커는 주기적으로 Zookeeper에 접속하면서 Session Hearbeat을 전송하여 자신의 상태를 보고한다.
- Zookeeper는 zookeeper.session.timeout.ms 이내에 Hearbeat을 받지 못하면 해당 브로커의 노드 정보를 삭제하고 컨트롤러 브로커에게 변경 사실을 통보
  - watch event 발생 
- 컨트롤러 브로커는 다운된 브로커가 관리하는 파티션들에 대해서 새로운 파티션 리더 선출을 수행
- 만일 다운된 브로커가 컨트롤러 브로커이면 모든 노드에게 해당 사실을 통보하고 가장 먼저 접속한 다른 브로커가 컨트롤러로 선출된다.

<img width="346" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/2d790242-6ec8-4758-ab94-eca44de04f63">

**주키퍼 console**

```text
./zookeeper-shell localhost:2181
```

<img width="673" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/fa3ecb66-ee11-4c86-92c4-fda6b8d9020f">

- ls / : 루트 디렉토리 파일 리스트

<img width="583" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/cf8a5d1b-dad8-48b3-a4b4-f516bdabc299">

- ls /controller: [],컨트롤러 파일은 리프 노드
- get /controller: {"version":1,"brokerid":1,"timestamp":"1704544728806"}, 현재 1번 브로커가 컨트롤러 브로커임을 확인할 수 있다.

<img width="685" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/4b62f289-37be-464a-a457-443a0c9cfcb5">

## 컨트롤러의 리더 선출 프로세스

<img width="447" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/1526b3b7-2a21-4c11-b147-fc8ce9fe4374">

- 브로커 3이 shutdown되고 주키퍼는 session 기간동안 Hearbeat이 오지 않으므로 해당 브로커 노드 정보 갱신
  - Z Node /brokers/ids/3 삭제
- 컨트롤러는 주키퍼를 모니터링 하던 중 Watch Event로 브로커 3에 대한 Down 정보를 받는다.
  - 리더 파티션 3을 옮겨야 한다.
- 컨트롤러는 다운된 브로커가 관리하던 파티션들에 대해 새로운 Leader/Follower 결정
  - 2번 브로커로 결정했다면 해당 브로커에 이벤트를 전달한다.
- 결정된 새로운 Leader/Follwer 정보를 주키퍼에 저장하고 해당 파티션을 복제하는 모든 브로커에게 새로운 Leader/Follwer 정보를 전달하고 새로운 Leader로 부터 복제 수행할 것을 요청
- 각각의 브로커들은 공통된 캐싱된 메타 정보를 가지고 있는데 컨트롤러는 모든 브로커에게 Methdatacache를 새로운 Leader/Follwer 정보로 갱신할 것을 요청

**브로커 1, 2, 3 중에 3번을 종료한 뒤 브로커 2번의 로그 메시지**

```text
[2024-01-07 15:14:59,595] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(pizza-topic-p3r3-2, m-brk-topic-bb-2, pizza-topic-p3r3-1) (kafka.server.ReplicaFetcherManager)
[2024-01-07 15:14:59,614] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Partition pizza-topic-p3r3-0 has an older epoch (7) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-01-07 15:14:59,616] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Partition pizza-topic-p3r3-0 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-01-07 15:14:59,620] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Partition m-brk-topic-bb-0 has an older epoch (7) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-01-07 15:14:59,623] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Partition m-brk-topic-bb-0 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-01-07 15:14:59,624] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Partition m-brk-topic-bb-1 has an older epoch (7) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-01-07 15:14:59,624] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Partition m-brk-topic-bb-1 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-01-07 15:14:59,624] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Partition topic-p3r3-2 has an older epoch (0) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-01-07 15:14:59,624] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Partition topic-p3r3-2 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-01-07 15:14:59,637] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(pizza-topic-p3r3-0, topic-p3r3-2, m-brk-topic-bb-0, m-brk-topic-bb-1) (kafka.server.ReplicaFetcherManager)
[2024-01-07 15:14:59,638] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(topic-p3r3-2 -> InitialFetchState(Some(w45tiXPTRvSDWd1jABBIQA),BrokerEndPoint(id=1, host=localhost:9092),1,0), m-brk-topic-bb-0 -> InitialFetchState(Some(letHs3b3TriP2e2OtT3e8A),BrokerEndPoint(id=1, host=localhost:9092),8,0), m-brk-topic-bb-1 -> InitialFetchState(Some(letHs3b3TriP2e2OtT3e8A),BrokerEndPoint(id=1, host=localhost:9092),8,0), pizza-topic-p3r3-0 -> InitialFetchState(Some(r50RbsWEQcGkcaL7yaj3CA),BrokerEndPoint(id=1, host=localhost:9092),8,0)) (kafka.server.ReplicaFetcherManager)
[2024-01-07 15:14:59,640] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2024-01-07 15:14:59,641] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2024-01-07 15:14:59,641] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2024-01-07 15:14:59,667] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(topic-p3r3-1) (kafka.server.ReplicaFetcherManager)
[2024-01-07 15:14:59,679] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(topic-p3r3-0) (kafka.server.ReplicaFetcherManager)
[2024-01-07 15:14:59,679] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(topic-p3r3-0 -> InitialFetchState(Some(w45tiXPTRvSDWd1jABBIQA),BrokerEndPoint(id=1, host=localhost:9092),1,0)) (kafka.server.ReplicaFetcherManager)
[2024-01-07 15:14:59,823] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition pizza-topic-p3r3-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-01-07 15:14:59,825] INFO [UnifiedLog partition=pizza-topic-p3r3-0, dir=/tmp/kafka-logs-02] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-01-07 15:14:59,825] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition topic-p3r3-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-01-07 15:14:59,825] INFO [UnifiedLog partition=topic-p3r3-0, dir=/tmp/kafka-logs-02] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-01-07 15:14:59,825] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition topic-p3r3-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-01-07 15:14:59,825] INFO [UnifiedLog partition=topic-p3r3-2, dir=/tmp/kafka-logs-02] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-01-07 15:14:59,825] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition m-brk-topic-bb-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-01-07 15:14:59,825] INFO [UnifiedLog partition=m-brk-topic-bb-0, dir=/tmp/kafka-logs-02] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-01-07 15:14:59,825] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition m-brk-topic-bb-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-01-07 15:14:59,825] INFO [UnifiedLog partition=m-brk-topic-bb-1, dir=/tmp/kafka-logs-02] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
```
 
- `Removed fetcher for partitions Set(pizza-topic-p3r3-2, m-brk-topic-bb-2, pizza-topic-p3r3-1)`
  - pizza-topic-p3r3-X : X는 파티션 번호
  - fetcher는 단순히 replica라고 생각하면 된다. (리더 파티션이 팔로워 파티션에 직접 복제를 하는 것이 아닌 실제로는 팔로워 파티션이 fetch해가는 개념)

## ISR(In-Sync-Replicas)의 이해 

- Follower들은 누구라도 Leader가 될 수 있지만, 단 ISR 내에 있는 Follower들만 가능
- 파티션의 Leader 브로커는 Follower 파티션의 브로카들이 Leader가 될 수 있는지 지속적으로 모니터링 수행하여 ISR 관리
  - 예를 들어, 리더 파티션의 오프셋은 50000인데, 특정 팔로워 파티션의 오프셋이 뒤쳐지는 경우가 존재하는지 등을 파악하여 ISR에서 제거
- Leader 파티션의 메시지를 Follower가 빠르게 복제하지 못하고 뒤쳐질 경우 ISR에서 해당 Follower는 제거되며 Leader가 문제가 생길 때 차기 Leader가 될 수 없음

### ISR 조건

- 브로커가 주키퍼에 연결되어 있어야함
- zookeeper.session.timeout.ms로 지정된 기간(기본 6초, 최대 18초)내에 Hearbeat을 지속적으로 Zookeeper로 보냄
- replica.lag.time.max.ms로 지정된 기간(기본 10초, 최대 30초)내에 Leader의 메시지를 지속적으로 가져가야함
  - 리더 파티션이 존재하는 브로커는 팔로워들이 제대로 데이터를 가져가는지 모니터링하면서 ISR을 관리

<img width="587" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/6d4a663b-d19f-4d07-b8a3-63f35eea3ec9">

<img width="545" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/8e4fe6b8-fdf1-48fe-b120-9d42c581073c">

- Follower는 Leader에게 Fetch 요청을 수행. Fetch 요청에는 Follower가 다음에 읽을 메시지의 offset 번호를 포함
- Leader는 Follower가 요청한 offset 번호와 현재 Leader 파티션의 가장 최신 offset 번호를 비교하여 Follower가 얼마나 Leader 데이터 복제를 잘 수행하고 있는지 판단

## min.insync.replicas의 이해

min.insync.replicas 파라미터는 브로커의 설정값(토픽에 설정도 가능)으로 Producer가 acks=all(-1)로 설공적으로 메시지를 보낼 수 있는 최소한의 ISR 브로커 개수를 의미

### Producer의 acks 설정에 따른 send 방식 - acks all

<img width="824" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/a713e94d-8fc3-4eca-a4cc-baeac15fca47">

- Producer는 Leader 브로커가 메시지 A를 정상적으로 받은 뒤 모든 Replicator에 복제를 수행한 뒤에 보내는 Ack 메시지를 받은 후 다음 메시지인 메시지 B를 바로 전송. (만약 오류 메시지를 브로커로부터 받으면 메시지 A를 재전송)
- 메시지 A가 모든 Replicator에 완벽하게 복사되었는지의 여부까지 확인후에 메시지 B를 전송
- 메시지 손실이 되지 않도록 모든 장애 상황을 감안한 전송 모드이지만 Ack를 오래 기다려야 하므로 상대적으로 전송속도가 느림


### min.insync.replicas 설정에 따른 Producer 전송

쉽게는 위와 같이 이해할 수 있지만 좀 더 자세히는 아래 처럼 동작한다.

<img width="807" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/acafe7d0-3062-43ae-830f-873983203081">

<img width="818" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/bc8df329-e701-4834-8c1a-b22130d069d0">

- acks=all인 경우에 min.insync.replicas 에 설정된 개수만큼만 브로커로부터 ack가 전송되면 성공으로 판단한다.
- 따라서 위와 같이 설정된 경우 브로커 3이 죽더라도 ack를 프로듀서에 보낸다. 

<img width="823" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/68ccc5aa-344e-4eed-a3c6-d9a3c1834556">

## Preferred Leader Election 이해

<img width="811" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/f3d295b2-5222-42f6-9b78-933f7e30a12a">

- `Replicas: 1,2,3`: 해당 결과에서 1이 Preferred Broker가 된다.

<img width="657" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/4bb95160-8930-4e65-a59e-ac8b36ac7fe8">

- 파티션별로 최초 할당된 Leader/Follower Broker 설정을 Preferred Broker로 그래도 유지 
- Broker가 shutdown후 재기동 될 때 Preferred Leader Broker를 일정 시간 이후에 재선출
- auto.leader.rebalance.enable=true로 설정하고 leader.imbalance.check.interval.seconds를 일정시간으로 설정(기본 300초)
  - 기본 설정으로 5분뒤에 브로커가 Replicas의 Preferred Broker와 다르다고 판단되면 Preferred Leader Election 수행 -> 리밸런싱

<img width="812" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/c7390c5b-f6f2-4dcb-8ac0-4ac3ea506974">

만약에 기존에 브로커가 3개 파티션 3 복제 3으로 하나의 브로커에 하나의 리더 파티션이 골고루 할당된 상태에서 2개의 브로커가 모두 shutdown되면
남은 브로커 하나에 모든 리더 파티션이 몰리게 된다. 이후에 shutdown되었던 브로커가 모두 재기동되어도 특정 브로커에 리더 파티션이 모두 몰리는 현상(leader skew)이 발생하므로 이를 해결하기 위한 옵션이 auto.leader.rebalance.enable=true이다.

<img width="867" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/dde10517-2d3f-4cca-910c-d47b688bbdf5">

> 5분뒤에 리밸런싱이 발생한 모습

브로커 2, 3 모두 shutdown되면 파티션 1,2,3의 리더 브로커는 브로커 1이 된다. 
브로커 1이 메시지가 추가로 계속 유입된 후 브로커 1까지 shutdown될 경우 이후 브로커 2, 3이 재기동 되어도 파티션 1,2,3은 리더 브로커가 될 수 없다.(브로커 1의 리더 파티션에 모든 데이터가 존재하기 때문)
이를 위해서 해당 옵션(auto.leader.rebalance.enable=true)이 존재한다. 

**테스트 브로커 1,2,3이 존재하는 상황에서 2,3을 종료하고 마지막으로 1을 종료한 뒤 2,1,3 순서로 브로커를 재기동한 모습**

<img width="863" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/646f81fc-c174-4822-b5e8-1cf278af0b10">

- 2를 기동했을때는 리더가 none
- 1을 기동하면 리더가 1
- 5분이 지나면 Preferred Leader Election이 발생

이때 만약 1번 브로커가 재기동이 어려운 상황이라면 다른 브로커를 리더로 올릴지 결정해야한다. (Unclean Leader Election, 데이터 손실 감수)
- 리더가 none이기 때문에 프로듀서, 컨슈머가 모두 동작을 하지 못하는 상황

## Unclean Leader Election 이해

<img width="414" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/0811a1fd-6c37-42ff-ab46-fce027bd86a3">

> 브로커 2,3이 먼저 shutdown되어서 정상적으로 복제가 되지 않은 상황

- 기존의 리더 브로커가 오랜 기간 살아나지 않을 경우 복제가 완료되지 않은(Out of sync) 팔로워 브로커가 리더가 될지 결정해야 한다.
- 이때 기존의 리더 브로커가 가진 메시지 손실 여부를 감수하고 복제가 완료되지 않은 팔로워 브로커가 리더가 되려면 unclean.leader.election=true로 설정하면 Unclean Leader Election을 수행한다.

```text
./kafka-configs --bootstrap-server localhost:9092 --entity-type topics --entity-name topic-p3r3 --describe --all | grep unclean

  unclean.leader.election.enable=false sensitive=false synonyms={DEFAULT_CONFIG:unclean.leader.election.enable=false}
```

```text
./kafka-configs --bootstrap-server localhost:9092 --entity-type topics --entity-name topic-p3r3 --alter --add-config unclean.leader.election.enable=true
```

위와 같이 설정한 뒤 shutdown 순서에 맞지 않게 브러커를 재기동하더라도 바로 리더가 선출되는것을 확인할 수 있다.

