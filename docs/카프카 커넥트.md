# 카프카 커넥트

## 카프카 커넥트 소개

<img width="360" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/68e9479c-33e5-4268-90dc-b55225492327">

카프카 커넥트는 카프카 오픈소스에 포함된 툴 중 하나로 데이터 파이프라인 생성 시 반복 작업을 줄이고 효율적인 전송을 이루기 위한 애플리케이션이다.
커넥트는 특정한 작업 형태를 템플릿으로 만들어놓은 커넥터를 실행함으로써 반복 작업을 줄일 수 있다.

- 소스 커넥터 : 소스 애플리케이션, DB로부터 토픽에 데이터를 넣는 쓰레드
- 싱크 커넥터 : 토픽의 데이터를 싱크 애플리케이션, DB로 넣는 쓰레드

쓰레드 형태로 실행되기 때문에 쓰레드의 개수를 늘려서 병렬처리가 가능하다.

### 커넥트 내부 구조

<img width="233" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/d775b42f-c8fe-4545-a7bc-ddfdfdd96a9e">

사용자가 커넥트에 커넥터 생성 명령을 내리면 커넥트는 내부에 커넥터와 태스크(로직을 처리하는 가장 작은 단위)를 생성한다.
커넥터는 태스크들을 관리한다. 태스크는 커넥터에 종속되는 개념으로 실질적인 데이터 처리를 한다. 
그렇기 때문에 데이터 처리를 정상적으로 하는지 확인하기 위해서는 각 태스크의 상태를 확인해야 한다.

커넥터 쓰레드도 별도로 생성되는데, 태스크가 몇개 실행되는지 각 태스크 설정 부분을 오케스트레이션하는 쓰레드이다.

## 커넥터

### 소스 커넥터, 싱크 커넥터

커넥터는 프로듀서 역할을 하는 소스 커넥터와 컨슈머 역할을 하는 싱크 커넥터 2가지로 나뉜다.

예를 들어, 파일을 주고받는 용도로 파일 소스 커텍터와 파일 싱크 커넥터가 있다고 가정하자.
파일 소스 커넥터는 파일의 데이터를 카프카 토픽으로 전송하는 프로듀서 역할을 한다. 그리고 파일 싱크 커넥터는 토픽의 데이터를 파일로 전송하는 컨슈머 역할을 한다.

MySQL, S3, MongoDB 등과 같은 저장소를 대표적인 싱크 애플리케이션, 소스 애플리케이션이라 볼 수 있다. 
즉, MySQL에서 카프카로 데이터를 보낼 때 그리고 카프카에서 데이터를 MySQL로 저장할 때 JDBC 커넥터를 사용하여 파이프라인을 생성할 수 있다.

예를 들어 MySQL에서 일회성 파이프라인의 경우에는 직접 프로듀싱 애플리케이션을 만드는 것도 좋은 방법이다.
하지만 소스 커넥터로 개발하게 된다면 이러한 파이프라인이 반복적으로 필요할 가능성에 대응하기 쉽다.
특정 테이블에서 데이터를 select 해올 때 처음에는 1개의 테이블에서 가져오지만 이후에는 여러 개의 테이블에서 데이터를 가져와서 각기 다른 토픽에 데이터를 넣어야 한다면 소스 커넉터를 사용하여 템플릿형태로 빠르게 개발할 수 있다.

모니터링도 쉽다.

### 커넥터 플로그인

<img width="264" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/1d1132ee-13af-4dc6-9fd8-c7a06e193d7d">

카프카 2.6에 포함된 커넥트를 실행할 경우 클러스터 간 토픽 미러링을 지원하는 미러메이커2 커넥터와 파일 싱크 커넥터, 파일 소스 커넥터를 기본 플러그인으로 제공한다.
이외에 추가적인 커넥터를 사용하고 싶다면 플러그인 형태로 커넥터 jar 파일을 추가하여 사용할 수 있다.
커넥터 jar 파일에는 커넥터를 구현하는 클래스를 빌드한 클래스 파일이 포함되어 있다. 커넥터 플러그인을 추가하고 싶다면 직접 커넥터 플러그인을 만들거나 이미 인터넷상에 존재하는 커넥터 플러그인을 가져다 쓸 수도 있다.

> Task, Connector java 파일을 만들어서 build

### 오픈소스 커넥터

직접 커넥터를 만들 필요가 없으면 커넥터 jar파일을 다운로드하여 사용할 수 있다는 장점이 있다.
HDFS 커넥터, AWS S3 커넥터, JDBC 커넥터, 엘라스틱서치 커넥터 등 100개가 넘는 커넥터들이 이미 공개되어 있다.

오픈소스 커넥터의 종류는 컨플루언트 허브에서 검색할 수 있다.

### 컨버터, 트랜스폼

사용자가 커넥터를 사용하여 파이프라인을 생성할 때 컨버터와 트랜스폼 기능을 옵션으로 추가할 수 있다.
커넥터를 운영할 때 반드시 필요한 설정은 아니지만 데이터 처리를 더운 풍부하게 도와주는 역할을 한다.

- 컨버터 : 데이터 처리를 하기 전에 스키마 변경을 도와준다. 
  - JsonConvertor, String Convertor, ByteArray Convertor, ...
  - 커스텀 컨버터를 작성하여 사용할 수도 있다.
- 트랜스폼 : 데이터 처리 시 각 메시지 단위로 데이터를 간단하게 변환하기 위한 용도로 사용
  - 예를 들어, JSON 데이터를 커넥터에서 사용할 때 트랜스폼을 사용하면 특정 키를 삭제하거나 추가할 수 있다.
  - Cast, Drop, ExtractField, ...

## 커넥트 배포 및 운영

### 커넥트를 실행하는 방법

커넥트를 실행하는 방법은 크게 두 가지가 있다. 
1. 단일 모드 커넥트 (standalone mode kafka connect)
2. 분산 모드 커넥트 (distributed mode kafka connect)

### 단일 모드 커넥트

<img width="446" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/41dd4a30-64cb-4fd7-be98-ca8d8110076e">

단일 모드 커넥트는 1개 프로세스만 실행되는 점이 특징인데, 단일 프로세스로 동작하기 때문에 고가용성이 구성이 되지 않아서 단일 장애점이 될 수 있다.
그러므로 단일 모드 커넥트 파이프라인은 주로 개발환경이나 중요도가 낮은 파이프라인을 운영할 때 사용한다.

### 분산 모드 커넥트

<img width="480" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/950c02ee-febc-4e3b-8472-fe3dd55f83d4">

분산 모드 커넥트는 2대 이상의 서버에서 클러스터 형태로 운영함으로써 단일 모드 커넥트 대비 안전하게 운영할 수 있다는 장점이 있다.
2개 이상의 커넥트가 클러스터로 묶이면 1개의 커넥트가 이슈 발생으로 중단되더라도 남은 1개의 커넥트가 파이프라인을 지속적으로 처리할 수 있기 때문이다.

분산 모드 커넥트는 데이터 처리량의 변화에도 유연하게 대응할 수 있다. 커넥트가 실행되는 서버 개수를 늘림으로써 무중단으로 스케일 아웃하여 처리량을 늘릴 수 있기 때문이다.
이러한 장점으로 상용환경에서 커넥트를 운영한다면 분산 모드 커넥트를 2대 이상으로 구성하고 설정하는 것이 좋다.

> 데이터 처리량이 줄었다면 기존의 커넥트를 종료하게되면 커넥트들이 모두 쓰레드로 구성되어 있어서 failover되어 graceful shutdown이 가능해진다. -> 다른 커넥트로 자동 분산

분산 모드 카프카 커넥트에 REST API로 특정 커넥터를 실행하라고 명령할 수 있다.

### 커넥트 REST API 인터페이스

<img width="712" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/a0784cbb-d938-4331-850b-4f2e37ff87a0">

REST API를 사용하면 현재 실행 중인 커넥트의 커넥터 플러그인 종류, 태스크 상태, 커넥터 상태 등을 조회할 수 있다.
커넥트는 8083 포트로 호출할 수 있으며 HTTP 메서드 기반 API를 제공한다.

## 단일 모드 커넥트

단일 모드 커넥트는 보통 디버깅, 테스트 용도로 사용된다.
단일 모드 커넥트를 실행하기 위해서는 단일 모드 커넥트를 참조하는 설정 파일인 connect-standalone.properties 파일을 수정해야 한다.

<img width="713" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/e1a16460-1408-4876-81be-5569d8edd302">
- offset.storage.file.filename : 단일 모드 커넥트에 필요한 오프셋 정보를 파일로 저

### 단일 모드 컨넥트 실행

단일 모드 컨게트를 실행 시에 파라미터로 커넥트 설정파일과 커넥터 설정파일을 차례로 넣어 실행하면 된다.

`connect-file-source.properties`

<img width="717" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/a8682793-d8de-4370-b96f-78ccd37df72f">
- connector.class : 커넥터 종류 지정

```text
./bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties
```

## 분산 모드 커넥트

<img width="506" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/0938c35b-8271-4722-961b-38f91d25ef08">

분산 모드 커넥트는 단일 모드 커넥트와 다르게 2개 이상의 프로세스 1개의 그룹으로 묶여서 운영된다.
이를 통해 1개의 커넥트 프로세스에 이슈가 발생하여 종료되더라도 살아있는 나머지 1개 커넥트 프로세스가 커넥터를 이어받아서 파이프라인을 지속적으로 실행할 수 있다는 특징이 있다.

분산 모드 커넥트를 실행할 때는 동일한 group.id로 지정해야 한다.
group.id를 지정하면 다른 서버에서 띄운 분산 모드 커넥트가 전부 동일한 클러스터로 묶이게 된다.

만약 REST Api로 커넥터를 실행을 요청하게되면 모든 분산 커넥트에서 설정을 공유하게된다.
공유받음에 따라서 전달받은 태스크가 분산되어 쓰레드로 실행된다.

데이터 처리량이 많아지면 동일한 group.id로 분산 모드 커넥트를 실행해서 scale out 하면된다.

`connect-distributed.properties`

<img width="627" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/cd1b274f-3e34-4f00-a854-a3af715ce9d7">

- offset.storage.topic : offset.storage에 대한 토픽
- config.storage.topic : config.storage에 대한 토픽
- status.storage.topic : status.storage에 대한 토픽

위 세개의 토픽은 커넥터를 운영할 때 필요한 오프셋, 정보, 상태를 담는 용도로 사용된다.

커넥트에 필요한 정보를 모두 토픽으로 관리히고 있기 떄문에 모든 커넥트가 종료되는 상황이라도 모든 내용을 복구할 수 있다.

커넥트 프로세스를 실행한다고 데이터 파이프라인 역할을 하는것은 아니다.
파이프라인 역할을 하는 스레드를 실행시키기 위해서는 REST Api를 통해 명령을 내려야한다.

## 커스텀 소스 커텍터

<img width="330" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/8f24407d-e7d5-4e40-aa36-f2d7ba87d64b">

소스 커넥터는 소스 애플리케이션 또는 소스 파일로부터 데이터를 가져와 토픽으로 넣는 역할을 한다.
오픈소스 커넥터를 사용해도 되지만 라이센스 문제나 로직이 원하는 요구사항과 맞지 않아서 직접 개발해야 하는 경우도 있는데 이때는 카프카 커넥트 라이브러리에서 제공하는 SourceConnector와 SourceTask 클래스를 사용하여 직접 소스 커넥터를 구현하면 된다.
직접 구현한 소스 커넥터를 빌드하여 jar파일로 만들고 커넥트를 실행 시 플러그인으로 추가하여 사용할 수 있다.

소스 커넥터를 만들 때는 connect-api 라이브러리를 추가해야 한다. connect-api 라이브러리에는 커넥터를 개발하기 위한 클래스들이 포함되어 있다.

**디펜던시 추가**

```groovy
dependencies {
  compile 'org.apache.kafka:connect-api:2.5.0'
}
```

> 해당 라이브러리를 빌드한 jar파일을 플러그인 형태로 커넥트에서 실행시키는 형태

### SourceConnector, SourceTask

**SourceConnector**

태스크를 실행하기 전 커넥터 설정파일을 초기화하고 어떤 태스크 클래스를 사용할 것인지 정의하는데에 사용한다.
그렇기 때문에 SourceConnector에는 실질적인 데이터를 다루는 부분이 들어가지 않는다. 

**SourceTask**

소스 애플리케이션 또는 소스 파일로부터 데이터를 가져와서 토픽으로 데이터를 보내는 역할을 수행한다.
SourceTask만의 특징은 토픽에서 사용하는 오프셋이 아닌 자체적으로 사용하는 오프셋을 사용한다는 점이다.
SourceTask에서 사용하는 오프셋은 소스 애플리케이션 또는 소스 파일을 어디까지 읽었는지 저장하는 역할을 한다. 이 오프셋을 통해 데이터를 중복해서 토픽으로 보내는 것을 방지할 수 있다.
예를 들어, 파일의 데이터를 한 줄씩 읽어서 토픽으로 데이터를 보낸다면 토픽으로 데이터를 보낸 줄 번호를 오프셋에 저장할 수 있다. (key = 줄 번호)

```java
public class TestSourceConnector extends SourceConnector {
  @Override
  public String version() {}

  @Override
  public void start(Map<String, String> props) {} // 옵션값 초기화

  @Override
  public Class<? extends Task> taskClass() {} // 실행하고자하는 소스 태스크 클래스

  @Override
  public List<Map<String, String>> taskConfigs(int maxTasks) {} // 태스크마다 다른 옵션

  @Override
  public ConfigDef config() {}

  @Override
  public void stop() {} // 커넥터 종료시에 리소스 정리 로직 넣는 부분
}
```

```java
public class TestSourceTask extends SourceTask { 
    @Override 
    public String version() {}

  @Override
  public void start(Map<String, String> props) {} // 커넥트에서 가져온 properties 파일을 가져와서 properties를 초기화 -> 예를 들어서 파일 시스템의 데이터를 토픽에 보내는 로직이 존재한다면 데이터에 대한 파일 리드를 해당 메서드를 통해 진행한다.

  @Override
  public List<SourceRecord> poll() {}

  @Override
  public void stop() {}
}
```

### 파일 소스 커넥터 구현 예제

> 파일 소스 커넥터는 파일을 읽어서 토픽에 데이터를 넣는 역할을 한다고 생각하면 된다.

로컬에 지정된 파일을 토픽으로 한줄씩 읽어서 토픽으로 보내는 파일 소스 커넥터를 작성한다.
소스 커넥터를 구현하기 전에 우선 build.gradle에 connect-api 라이브러리와 빌드된 파일을 jar로 압축하기 위한 스크립트를 작성한다.
카프카 커넥터를 직접 개발하고 플러그인으로 커넥트에 추가할 때 주의할 점은 사용자가 직접 작성한 클래스 뿐만 아니라 참조하는 라이브러리도 함께 빌드하여 jar로 압축해야한다는 점이다.

```groovy
jar {
  from {
    configurations.compile.collect { it.isDirectory() ? it : zipTree(it) }
  }
}
```

## 커넥터 옵션값 설정시 중요도(Importance) 지정 기준

커넥터를 개발할 때 옵션값의 중요도를 Importance enum 클래스로 지정할 수 있다. Importance enum 클래스는 HIGH, MEDIUM, LOW 3가지 종류로 나뉘어 있다.
하지만 해당 옵션은 사용자로 하여금 중요한다는 것을 명시적으로 표시하기 위한 문서로 사용할 뿐이다
그러므로 커넥터에서 반드시 사용자가 입력한 설정이 필요한 값은 HIGH, 사용자의 입력값이 없더라도 상관없고 기본값이 있는 옵션을 MIDIUM, 사용자의 입력값이 없어도되는 옵션을 LOW 정도로 구분하여 지정하면 된다.

## 커스텀 싱크 커텍터

<img width="326" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/df4d558e-752e-44b2-b382-0637e496d63a">

싱크 커넥터는 토픽의 데이터를 타깃 애플리케이션 또는 타깃 파일로 저장하는 역할을 한다.
카프카 커넥트 라이브러리에서 제공하는 SinkConnector와 SinkTask 클래스를 사용하면 직접 싱크 커넥터를 구현할 수 있다.
직접 구현한 싱크 커넥트는 빌드하여 jar로 만들고 커넥트의 플러그인으로 추가하여 사용할 수 있다.

```kotlin
class TestSinkConnector: SinkConnector() {
    override fun version(): String {}

    override fun start(props: MutableMap<String, String>?) {}

    override fun taskClass(): Class<out Task> {}

    override fun taskConfigs(maxTasks: Int): MutableList<MutableMap<String, String>> {}

    override fun stop() {}

    override fun config(): ConfigDef {}
}
```

```kotlin
class TestSinkTask: SinkTask() {
    override fun version(): String {}

    override fun start(props: MutableMap<String, String>?) {} // 자원 초기화 -> ex. DB 초기화, ..

    override fun stop() {} // 리소스 해제

    override fun put(records: MutableCollection<SinkRecord>?) {} // 레코드를 가져와서 처리 -> 컨슈머의 poll()과 동일

  override fun flush(currentOffsets: MutableMap<TopicPartition, OffsetAndMetadata>?) { // 어떤 오프셋까지 처리되었는지를 확인
    super.flush(currentOffsets)
  }
}
```

<img width="576" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/01bbb0de-35fa-4270-bfb0-b9776826a4dc">

## 분산 카프카 커넥트

<img width="678" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/4a7facaf-264a-4d94-b9fc-36c6d1626756">

### 분산 모드 커넥트 실행, 플러그인 확인

<img width="586" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/4b3acc89-549d-4c3d-9e48-68d7cee09051">

### FileStreamSinkConnector 테스트

<img width="586" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/156e9de8-31c9-4e4a-a5f2-34091cefd7a8">

카프카 커넥터를 활용하면 REST api를 통해서 파이프라인을 간편하고 반복적으로 생성할 수 있다.

### 실행 확인

<img width="599" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/e43d77ff-0df9-4e38-bd8d-f2bcf1721a79">
