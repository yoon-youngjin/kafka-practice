# 카프카 스트림즈

<img width="494" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/dcce8d48-2add-48c5-a61a-c32352f3c54c">

**카프카 스트림즈는 토픽에 적재된 데이터를 실시간으로 변환하여 다른 토픽에 적재하는 라이브러리이다.**

스트림즈는 카프카에서 공싱적으로 지원하는 라이브러리로 매번 카프카 버전이 오를 때마다 스트림즈 자바 라이브러리도 같이 릴리즈된다.
그렇기 때문에 자바 기반 스트림즈 애플리케이션은 카프카 클러스터와 완벽하게 호환되면서 스트림 처리에 필요한 편리한 기능들을 제공한다.

스트림즈 애플리케이션 또는 카프카 브로커의 장애가 발생하더라도 정확히 한번할 수 있도록 장애 허용 시스템을 가지고 있어서 데이터 처리 안정성이 매우 뛰어나다.
카프카 클러스터를 운영하면서 실시간 스트림 처리를 해야하는 필요성이 있다면 카프카 스트림즈 애플리케이션으로 개발하는 것을 1순위로 고려하는 것이 좋다.

### 프로듀서와 컨슈머를 조합하지 않고 스트림즈를 사용해야 하는 이유

스트림 데이터 처리에 있어 필요한 다양한 기능을 스트림즈DSL로 제공하며 필요하다면 프로세서 API를 사용하여 기능을 확장할 수 있기 때문이다.
컨슈머와 프로듀서를 조합하여 스트림즈가 제공하는 기능과 유사하게 만들 수 있다. 그러나 스트림즈 라이브러리를 통해 제공하는 단 한 번의 데이터 처리, 장애 허용 시스템 등의 특징들은 컨슈머와 프로듀서의 조합만으로는 완벽하게 구현하기 어렵다.

다만, 스트림즈가 제공하지 못하는 기능을 구현할 때는 컨슈머와 프로듀서를 조합하여 구현하면 좋다.
예를 들어, 소스 토픽(사용하는 토픽)과 싱크 토픽(저장하는 토픽)의 카프카 클러스터가 서로 다른 경우는 스트림즈가 지원하지 않으므로 이때는 컨슈머와 프로듀서 조합으로 직접 클러스터를 지정하는 방식으로 개발할 수 있다.

### 스트림즈 내부 구조

<img width="262" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/6fc524c6-ef08-49d0-b3fa-ac1f130b43c3">

스트림즈 애플리케이션은 내부적으로 스레드를 1개 이상 생성할 수 있으며, 스레드는 1개 이상의 태스크를 가진다.

> 태스크 : 스트림즈 애플리케이션을 실행하면 생기는 데이터 처리 최소 단위

만약 3개의 파티션으로 이루어진 토픽을 처리하는 스트림즈 애플리케이션을 실행하면 내부에 3개의 태스트가 생긴다. 컨슈머의 벙렬처리를 위해 컨슈머 그룹으로 이루어진 컨슈머 스레드를 여러 개 실행하는 것과 비슷하다고 볼 수 있다.
카프카 스트림즈는 컨슈머 스레드를 늘리는 방법과 동일하게 병렬처리를 위해 파티션과 스트림즈 스레드(또는 프로세스) 개수를 늘림으로써 처리량을 늘릴 수 있다.

파티션 3개의 토픽에서 데이터를 가져가는 스트림즈 애플리케이션에서는 자동으로 태스크가 3개가 생겨서 운영된다.
위 그림에서는 스레드가 1개만 존재하지만 3개로 운영한다면 각각의 스레드에서 태스크가 실행되어 병렬처리가 가능하다.
혹은 n개의 프로세스를 운영할 수도 있다.

### 스트림즈 애플리케이션 스케일 아웃

<img width="385" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/2680dd95-6b25-478d-b255-62b3f6a12cc9">

실제 운영환경에서는 장애가 발생하더라도 안정적으로 운영할 수 있도록 2개 이상의 서버로 구성하여 스트림즈 애플리케이션을 운영한다. 
이를 통해 일부 스트림즈 애플리케이션 또는 애플리케이션이 실행되는 서버에 장애가 발생하더라도 안전하게 스트림 처리를 할 수 있다.

> 컨슈머에서 group.id를 지정하게 되면 동일한 컨슈머 그룹에서 운영되는데 스트림즈 애플리케이션에서는 group.id라는 개념이 없고 application.id라는 개념이 존재한다.

### 토폴로지 

<img width="503" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/ffcf9dd3-1528-4a09-832d-5e88ef95e63e">

카프카 스트림즈의 구조와 사용 방법을 알기 위해서는 우선 토폴로지와 관련된 개념을 익혀야 한다.
토폴로지란 2개 이상의 노드들과 선으로 이루어진 집합을 뜻한다. 스트림즈에서 사용하는 토폴로지는 트리 형태와 유사하다.

### 프로세서와 스트림

<img width="384" alt="image" src="https://github.com/yoon-youngjin/kafka-practice/assets/83503188/f7d4afb8-c765-46d2-84ac-dd5ad4b35dc0">

스트림즈에서는 토폴로지를 이루는 노드를 하나의 **프로세서**라고 부르고 노드와 노드를 이은 선음 **스트림**이라고 부른다. 
스트림은 토픽의 데이터를 뜻하는데 프로듀서와 컨슈머에서 사용했던 레코드와 동일하다.

- 소스 프로세서 : 데이터를 처리하기 위해 최초로 선언해야 하는 노드로, 하나 이상의 토픽에서 데이터를 가져오는 역할을 한다.
- 스트림 프로세서 : 다른 프로세서가 반환한 데이터를 처리하는 역할을 한다.
  - 변환, 분기처리와 같은 로직이 데이터 처리의 일종
- 싱크 프로세서 : 데이터를 특정 카프카 토픽으로 저장하는 역할을 하며 스트림즈로 처리된 데이터의 최종 종착지다.
  - 특정 토픽을 다른 토픽에 데이터를 저장하는 것

> 스트림즈를 사용해서 애플리케이션을 개발하는 것은 특정 토픽에 있는 데이터를 스트림 데이터 처리 이후에 다른 토픽에 저장하는 것이다.

### 스트림즈 DSL과 프로세서 API

스트림즈에서 구현하는 방식은 크게 스트림즈 DSL, 프로세서 API 2가지 방법으로 가능하다.
스트림즈 DSL은 스트림 프로세싱에 쓰일 만한 다양한 기능들을 자체 API로 만들어 놓았기 때문에 대부분의 변환 로직을 어렵지 않게 개발할 수 있다.
만약 스트림즈 DSL에서 제공하지 않는 일부 기능들의 경우 프로세서 API를 사용하여 구현할 수 있다.

**스트림즈DSL로 구현하는 데이터 처리 예시**
- 메시지 값을 기반으로 토픽 분기 처리
- 지난 10분간 들어온 데이터의 개수 집계
- count, aggregation, map, flatmap과 같은 메서드, ...

**프로세서API로 구현하는 데이터 처리 예시**
- 메시지 값의 종류에 따라 토픽을 가변적으로 전송
- 일정한 시간 간격(interval)으로 데이터 처리

## 스트림즈DSL

스트림즈DSL로 구성된 애플리케이션을 코드로 구현하기 전에 스트림즈DSL에서 다루는 새로운 개념들에 대해 짚고 넘어가야 한다.
스트림즈 DSL에는 레코드의 흐름을 추상화한 3가지 개념인 KStream, KTable, GlobalKTable이 있다. 해당 개념은 스트림즈DSL에서만 사용되는 개념이다.

### KStream

<img width="328" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/620e4013-8271-463b-afe0-934cb2a422cd">

KStream은 레코드의 흐름을 표현한 것으로 메시지 키와 메시지 값으로 구성되어 있다.
KStream으로 데이터를 조회하면 토픽에 조냊하는(또는 KStream에 존재하는) 모든 레코드가 출력된다. KStream은 컨슈머로 토픽을 구독하는 것과 동일한 선상에서 사용하는 것이라고 볼 수 있다.

### KTable

<img width="331" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/d44e70ee-82a1-41e1-8044-59ad9b1a4d72">

KTable은 KStream과 다르게 메시지 키를 기준으로 묶어서 사용한다. KStream은 토픽의 모든 레코드를 조회할 수 있지만 KTable은 유니크한 메시지 키를 기준으로 가장 최신 레코드를 사용한다.
그러므로 KTable로 데이터를 조회하면 메시지 키를 기준으로 가장 최신에 추가된 레코드의 데이터가 출력된다.
새로 데이터를 적재할 때 동일한 메시지 키가 있을 경우 데이터가 업데이트 되었다고 볼 수 있다. 왜냐하면 메시지 키의 가장 최신 레코드가 추가되었기 때문이다.

> key-value 스토어와 비슷하다.

### 코파티셔닝 

<img width="319" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/eebcecd1-911d-4bbf-92ff-5ba31842d6a0">

KStream과 KTable 데이터를 조인한다고 가정하자. KStream과 KTable을 조인하려면 반드시 코파티셔닝(co-partitioning)되어 있어야 한다.
- 코파티셔닝 : 조인을 하는 2개 데이터의 파티션 개수가 동일하고 파티셔닝 전략(파티셔너의 전략)을 동일하게 맞추는 전략

파티션 개수가 동일하고 파티셔닝 전략이 같을 경우에는 동일한 메시지 키를 가진 데이터가 동일한 태스크에 들어가는 것을 보장한다. 이를 통해 각 태스크는 KStream의 레코드와 KTable의 메시지 키가 동일할 경우 조인을 수행할 수 있다.

### 코파티셔닝되지 않은 2개 토픽의 이슈

<img width="304" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/1a608499-93ee-4165-b974-9a76e810d71b">

문제는 조인을 수행하려는 토픽이 코파티셔닝되어 있음을 보장할 수 없다는 것이다. KStream과 KTable로 사용하는 2개의 토픽이 파티션 개수가 다를 수도 있고 파티션 전략이 다를 수도 있다.
이런 경우에는 조인을 수행할 수 없다. 코파티셔닝되지 않은 2개의 토픽을 조인하는 로직이 담긴 스트림즈 애플리케이션을 실행하면 TopologyException이 발생한다.

> 두 가지 조건(파티션 개수, 파티셔닝 전략)이 만족하지 않으면 조인하고자 하는 데이터가 동일한 파티션에 들어간다고 보장할 수 없을뿐더러 파티션 개수가 다르기 때문에 태스크에 모두 정상적으로 할당될 수 없다.

이러한 경우 사용할 수 있는 것이 GlobalKTable이다.

### GlobalKTable

<img width="304" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/3b260e25-483d-44c3-9944-7f37e2b4932e">

## 스트림즈 주요 옵션

### 스트림즈DSL 필수 옵션

- bootstrap.server : 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트 이름:포트를 1개 이상 작성한다. 2개 이상 브로커 정보를 입력하여 일부 브로커에 이슈가 발생하더라도 접속하는 데에 이슈가 없도록 설정 가능하다.
- application.id : 스트림즈 애플리케이션을 구분하기 위한 고유한 아이디를 설정한다. 다른 로직을 가진 스트림즈 애플리케이션들은 서로 다른 application.id 값을 가져야 한다.
  - 스트림즈 애플리케이션을 그룹별로 묶기 위한 값 (group-id와 비슷)
  - application.id가 동일한 경우에 동일한 로직의 애플리케이션 N개를 띄워서 병렬처리하는 것과 같다.

### 스트림즈DSL 선택 옵션

- default.key.serde : 레코드의 메시지 키를 직렬화, 역직렬화하는 클래스를 지정한다. 기본값은 바이트 직렬화, 역직렬화 클래스인 Serdes.ByteArray().getClass().getName()
- default.value.serde : 레코드의 메시지 값을 직렬화, 역직렬화하는 클래스를 지정한다. 기본값은 바이트 직렬화, 역직렬화 클래스인 Serdes.ByteArray().getClass().getName()
- num.stream.threads : 스트림 프로세싱 실행 시 실행될 스레드 개수를 지정한다. 기본값은 1
- state.dir : 상태기반 데이터를 처리할 때 데이터를 저장할 디렉토리를 지정한다. 기본값은 /tmp/kafka-streams

### 필터링 스트림즈 애플리케이션

<img width="267" alt="image" src="https://github.tossbank.it/storage/user/490/files/e1915453-600e-42e0-ab3e-eb219a636197">

토픽으로 들어온 문자열 데이터 중 문자열 길이가 5보다 큰 경우만 필터링하는 스트림즈 애플리케이션을 스트림 프로세서를 사용하여 만들 수 있다.
메시지 키 또는 메시지 값을 필터링하여 특정 조건에 맞는 데이터를 골라낼 때는 filter() 메서드를 사용하면 된다. filter() 메서드는 스트림즈DSL에서 사용 가능한 필터링 스트림 프로세서이다.

## KStream, KTable 조인 스트림즈 애플리케이션
 
KTable과 KStream은 메시지 키를 기준으로 조인할 수 있다.
대부분의 데이터베이스는 정적으로 저장된 데이터를 조인하여 사용했지만 카프카에서는 실시간으로 들어오는 데이터들을 조인할 수 있다.
사용자의 이벤트 데이터를 데이터베이스에 저장하지 않고도 조인하여 스트리밍 처리할 수 있다는 장점이 있다.

<img width="296" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/e7604062-c480-4590-8683-0cd344915b44">

만약에 KStream에는 주문 데이터, KTable에는 주소 데이터가 들어간다고 가정해보자. 
이러한 경우 두 데이터를 조인해서 해당 주문이 어떤 주소로 가야할지 스트림 데이터를 출력할 수 있다.
따라서 이벤트 데이터를 DB와 연동하지 않고도 스트리밍 처리할 수 있다는 장점이 있다.

<img width="367" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/c8f8345c-5201-47ef-a2a2-7b66682765ec">

> KTable과 KStream을 조인한다는 것은 동일한 키에 대해서 메시지 값을 조인해서 출력하는 것을 의미한다. 

이름을 메시지 키, 주소를 메시지 값으로 가지고 있는 KTable이 있고 이름을 메시지 키, 주문한 물품을 메시지 값으로 가지고 있는 KStream이 존재한다고 가정하자.
사용자가 물품을 주문하면 이미 토픽에 저장된 이름:주소로 구성된 KTable과 조인하여 물품과 주소가 조합된 데이터를 새로 생성할 수 있디.

굉장히 낮은 latency로 대용량 데이터를 처리할 수 있다는 장점이 있다.

**만약 주소가 변경되는 경우?**

KTable은 동일한 메시지 키가 들어올 경우 가장 마지막의 레코드를 유효한 데이터로 보기 때문에 가장 최근에 바뀐 주소로 조인을 수행할 것이다.

**join을 위한 토픽 생성**

```text
./bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --partitions 3 --topic address

./bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --partitions 3 --topic order

./bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --partitions 3 --topic order_join
```
- 위에서 주요한 점은 파티션 개수가 모두 동일하다는 것이다.

## KStream, GlobalKTable 조인 스트림즈 애플리케이션 

<img width="341" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/16d0032e-1c2a-4f86-b543-535a7afdaed6">

앞선 예제에서 order 토픽과 address 토픽은 코파티셔닝되어 있으므로 각각 KStream과 KTable로 선언해서 조인을 할 수 있었다.
그러나 코파티셔닝 되어있지 않은 토픽을 조인해야할 때는 어떻게 해야 할까?

1. 리파티셔닝을 수행한 이후 코파티셔닝이 된 상태로 조인 
2. KTable로 사용하는 토픽을 GlobalKTable로 선언

> 스트림즈 애플리케이션에서 코파티셔닝이란 각 토픽을 동일한 개수의 파티션 개수로 맞추는 것을 의미한다.
 
## 스트림즈DSL의 윈도우 프로세싱

스트림 데이터를 분석할 때 가장 많이 활용하는 프로세싱 중 하나는 윈도우 연산이다. 
윈도우 연산은 특정 시간에 대응하여 취합 연산을 처리할 때 활용한다.

카프카 스트림즈에서는 윈도우 프로세싱 4가지를 지원한다.
모든 프로세싱은 메시지 키를 기준으로 취합되기 때문에 해당 토픽에 동일한 파티션에는 동일한 메시지 키가 있는 레코드가 존재해야지만 정확한 취합이 가능하다.
만약 커스텀 파티셔너를 사용하여 동일 메시지 키가 동일한 파티션에 저장되는 것을 보장하지 못하거나 메시지 키를 넣지 않으면 관련 연산이 불가능하다.

1. 텀블링 윈도우
2. 호핑 윈도우
3. 슬라이딩 윈도우
4. 세션 윈도우

### 텀블링 윈도우

<img width="621" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/be606b2d-cded-4145-8445-f0a5bf56269b">

텀블링 윈도우는 서로 겹치지 않은 윈도우를 특정 간격으로 지속적으로 처리할 때 사용한다. 
윈도우 최대 사이즈에 도달하면 해당 시점에 데이터를 취합하여 결과를 도출한다.
텀블링 윈도우는 단위 시간당 데이터가 필요할 경우 사용할 수 있다. 예를 들어 매 5분간 접속한 고객의 수를 츠정하여 방문자 추이를 실시간 취합하는 경우 텀블링 윈도우를 사용할 수 있다.

위 사진에서 노란 레코드의 경우 5초마다 취합하여 DB에 데이터를 적재한다면 총 7번의 insert가 아닌 4번의 요청으로 모두 적재할 수 있다.

텀블링 윈도우를 사용하기 위해서는 groupByKey와 windowedBy를 사용해야 한다. windowedBy의 파라미터는 텀블링 윈도우의 사이즈를 뜻한다.
이후 텀블링 연산으로 출력된 데이터는 KTable로 커밋 interval 마다 출력된다.

### 호핑 윈도우

<img width="625" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/2cee9c33-3753-4dec-8765-5eb748c65a1b">

호핑 윈도우는 일정 시간 간격으로 겹치는 윈도우가 존재하는 윈도우 연산을 처리할 경우 사용한다.
호핑 윈도우는 윈도우 사이즈와 윈도우 간격 2가지 변수를 가진다. 윈도우 사이즈는 연산을 수행할 최대 윈도우 사이즈를 뜻하고 윈도우 간격은 서로 다른 윈도우 간 간격을 뜻한다.
텀블링 윈도우와 다르게 동일한 키의 데이터는 서로 다른 윈도우에서 여러번 연산될 수 있다.

### 슬라이딩 윈도우

<img width="641" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/6991d659-d8f9-4a0e-a873-4060fa01fa92">

슬라이딩 윈도우는 호핑 윈도우와 유사하지만 데이터의 정확한 시간을 바탕으로 윈도우 사이즈에 포함되는 데이터를 모두 연산에 포함시키는 특징이 있다.
여기서 말하는 정확한 시간은 각각의 레코드에 포함된 Timestamp를 의미한다.

### 세션 윈도우

<img width="612" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/cc4d262f-8859-4e54-8b5d-39c58184be31">

세션 윈도우는 동일 메시지 키의 데이터를 한 세션에 묶어 연산할 때 사용한다.
세션의 최대 만료시간에 따라 윈도우 사이즈가 달라진다. 세션 만료 시간이 지나게 되면 세션 윈도우가 종료되고 해당 윈도우의 모든 데이터를 취합하여 연산한다.
그렇기 때문에 세션 윈도우 사이즈는 가변적이다. (차별점)

**윈도우 연산시 주의해야할 사항**

<img width="634" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/106c2b15-bff1-4f59-9014-e43665af5283">

카프카 스트림즈는 커밋(기본 값 30초)을 수행할 때 윈도우 사이즈가 종료되지 않아도 중간 정산 데이터를 출력한다.
커밋 시점마다 윈도우의 연산 데이터를 출력하기 때문에 동일 윈도우 사이즈(시간)의 데이터는 2개 이상 출력 될 수 있다.

<img width="640" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/8632b797-b384-4960-9d6e-d060e0ec2b9b">

최종적으로 각 윈도우에 맞는 데이터를 출력하고 싶다면 windowed를 기준으로 동일 윈도우 시간 데이터는 겹쳐쓰기(upsert)하는 방식으로 처리하는 것이 좋다.
예를 들어 0~5초의 A 데이터가 포함된 윈도우 취합 데이터가 들어오면 해당 데이터를 유니크 키로 설정하고 새로 들어온 데이터를 겹쳐쓰는 것이다.
위 경우에는 최초에 0~5초 A데이터가 2개 취합된 데이터가 처음 저장되고, 추후에 6초에 출력된 3개 취합된 데이터가 최종 저장된다. 결과적으로 A가 0~5초에 3개 count된 것을 확인할 수 있게 된다.

> 동일 간격에서 최신 데이터만 출력 OR 겹쳐쓰기 

## 스트림즈DSL의 Queryable store

카프카 스트림즈에서 KTable은 카프카 토픽의 데이터를 로컬의 rocksDB에 Materialized View로 만들어두고 사용하기 때문에 레코드의 메시지 키, 메시지 값을 기반으로 keyValueStore로 사용할 수 있다.
특정 토픽을 KTable로 사용하고 ReadOnlyKeyValueStore로 뷰를 가져오면 메시지 키를 기반으로 토픽 데이터를 조회할 수 있게 된다.
마치 카프카를 사용하여 로컬 캐시를 구현한것과 유사하다고 볼 수 있다.

```java
ReadOnlyKeyValueStore<String, String> keyValueStore;
StreamBuilder builder = new StreamBuilder();
KTable<String, String> addressTable = builder.table(ADDRESS_TABLE, Materialized.as(ADDRESS_TABLE))

keyValueStore = streams.store(StoreQueryParameters.fromNameAndType(ADDRESS_TABLE, QueryableStoreTypes.keyValueStore()));
keyValueIterator<String, String> address = keyValueStore.all();
address.forEachRemaining(keyValue -> log.info(keyValue.toString()));
```

## 프로세서 API

프로세서API는 스트림즈DSL보다 투박한 코드를 가지지만 토폴로지를 기준으로 데이터를 처리한다는 관점에서 동일한 역할을 한다.
스트림즈DSL은 데이터 처리, 분기, 조인을 위한 다양한 메서드들을 제공하지만 추가적인 상세 로직의 구현이 필요하다면 프로세서 API를 활용할 수 있다.

프로세서API를 구현하기 위해서는 Processor 또는 Transformer 인터페이스로 구현한 클래스가 필요하다. Processor 인터페이스는 일정 로직이 이루어진 뒤 다음 프로세서로 데이터가 넘어가지 않을 때 사용한다. 
반면에 Transformer 인터페이스는 일정 로직이 이루어진 뒤 다음 프로세서로 데이터를 넘길 때 사용한다.

<img width="552" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/10a539f7-b133-4a60-97f3-49dc759bebe1">

<img width="525" alt="image" src="https://github.com/yoon-youngjin/spring-study/assets/83503188/b2a9042a-9529-48f2-a46c-b978053d437a">
